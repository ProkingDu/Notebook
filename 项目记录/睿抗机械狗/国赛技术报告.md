
# 作品概述

之前我们队伍在省赛的控制策略是基于Python的flask传输视频流，在头部板卡启动flask服务器并且将视频流发送到运动控制板卡上，在运动控制板接收图像并且进行处理来完成循迹任务。

后来实战的表现，由于树莓派的性能有限，加上大量的图像处理算法使得系统响应延迟较高，这一流程需要接收图像、处理图像、计算参数、控制运动，即使我们使用多线程的方式来解决问题，仍然无法突破性能瓶颈。

因此在国赛准备阶段我们优化了系统设计结构。

首先是整体的架构，本次我们使用三个板卡联动来完成任务。包括通过在运动控制板卡（161）上搭载Unitree Legged SDK来控制机器人运动，并且开启一个socket服务器来监听控制消息，同时将消息划分为机器人控制指令和机械臂控制指令，也就是说，所有的运动控制部分都在161运动控制板卡上完成。

同时，接着采用头部板卡作为相机图像来源，依据头部相机的实时图像来计算机器人运动参数，在之前的业务逻辑中，仅通过划分ROI区域来计算机器人转弯角度，而没有考虑到横向水平移动来保持机器人在赛道中间，因此在优化后的系统中，我们通过划分更多的ROI区域来计算更加精确的运动轨迹。这一步的的大致逻辑是，首先是从图像中提取黄色的赛道线区域，随后计算中点以及中点坐标，然后通过二次多项式拟合直线曲率，随后根中线相对图像中心位置的偏移量和直线的曲率决定是否横向移动和调整前进角度。

这一部分的业务在机器人内部的14板卡（即双侧相机板卡）实现。在头部板卡我们使用Unitree_camera_sdk来传输图像，同时开启传输面部相机和下巴相机的图像，在14板卡通过Python程序接收UDP视频流，并且将每一帧图像存入队列中。

14板卡是整个系统的核心业务板卡，一方面需要接收图像并且存入队列中，另一方面需要读取队列中的图像。由于队列先进先出和取出不放回的特性，能够极大的提高图像处理效率和降低误差。同时考虑到弱化图像处理性能的影响，我们限制了队列的最大长度，当队列长度过长时则抛弃较早的数据，给于机器人更加即时的响应性。

由于14板卡还需要对图像进行处理，因此我们通过多线程的方式运行，首先开启获取图像并且存入队列的线程，随后开启运动控制的线程，实时通过队列中的图像计算，如果需要对机器人进行运动控制则向运动控制板卡发送socket消息。


# 模块设计

## 整体架构

在整个系统的设计中，我们采用模块化的方式进行开发，以提高整个系统的灵活性以及可定制性，同时更加便于二次开发。

系统的整体架构图如下：
![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/996708feb77fec882ad9f35a58bdd84e.png)



## 模块分析

在进行模块化设计之前，针对各个所用到的板卡，我们对其进行的详细的模块分析以及设计解决方案，图示如下：
![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/477685fe68fb2dfdbfc21e5b2d2716f6.png)


我们系统解决的重点问题如下：

1. 通过SDK对机器人控制
2. 通过CameraSDK获取双目鱼眼相机的视频帧
3. 在板卡间传输视频流
4. 对视频流进行处理，分割出图像
5. 对图像进行处理，得出赛道部分并决定移动方式
6. 实现Socket服务器
7. 通过客户端连接socket
8. 发送socket消息并且执行动作
9. 识别标记点卸载物资
10. 通过状态机模型在不同的标记点执行不同逻辑
11. 物资识别程序
13. 机械臂的运动控制程序设计
14. 机械臂与机器人的串口通信
15. 控制机械臂抓取和卸载物资

# Part I 机械臂设计

## 1. 整体设计

我们的机械臂结构图如下所示：
![小杜的个人图床](http://src.xiaodu0.com/2024/05/17/3e776fa8ef75469cb8e070006663739b.png)
其中标记的S0、S1、S2、S3、S4、S5的节点即为总线舵机，通过这六个舵机的转向来实现机械臂整体的运动。

其中舵机000为底部云台舵机，控制机械臂整体旋转，001为云台上方摆动舵机，控制机械臂整体在水平方向的前后移动。编号002为小臂控制舵机，用于控制小臂前后摆动，编号003为爪子摆动舵机，用于控制爪子在水平方向的前后摆动，004为爪子转向舵机，用于控制爪子在水平方向的左右旋转，005为爪子开合舵机，控制爪子开合。

实物图如下所示：
![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/6266b2b4d87e945694f28d2acac49264.jpg)

由于我们物料体积的问题，在机械臂组装之后，我们更换了新的爪子来适配物料的抓取。

我们的机械臂是购买了一套组装的套件，自行手动安装完成的，在程序设计上，一部分参考商家提供的出厂示例程序，另一部分根据作品需求进行二次开发。

## 2. 结构组成

这一部分介绍我们设计的机械臂所使用的零件以及其在整体中的功能。

1. 云台与云台舵机和组装螺丝，用于控制机械臂底部旋转与提供支撑
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/abce0d02c2b347ea908b3593d4864067.png)

![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/bfbf21b6b4740d11f7683abafc270553.png)

2. 云台支撑结构，用于支持云台，提供稳定作用

![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/320303f23c1cb037a5c0e7925f236356.png)

3. U型舵机支架 用于固定伸展舵机，防止过重导致的损坏
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/ffde83da34c90c81c1bdae110e297000.png)

4. 舵机与牵动盘口 为伸展舵机提供牵动与稳定功能。
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/7b29cb57750f61143f1026899fd85124.png)

5. 短C型舵机支架 用于连接两个伸展舵机，提高承重。
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/ad7d3b7acba1c3f6b95d5594ed9d9f57.png)

6. 凹凸直立舵机支架，用于连接爪子舵机与爪子旋转舵机
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/1e46b69431b9609ef7974623893144c9.png)

7. 金属舵盘，用于为爪子旋转提供牵引和保持稳定。
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/fbb6b434492f45da6f6eef9e70fee31c.png)
8. 组合后示意图：
![小杜的个人图床](http://src.xiaodu0.com/2024/06/29/a530ca5cebb4993efdb80c6e504f97cb.png)

## 3. 程序开发与烧录

### (1).出厂程序烧录

商家提供了控制板与开发板的基础示例程序用于集成开发，我们通过将示例程序烧录到开发板中作为接口使用来二次开发实现目的的业务控制。
出厂程序使用C语言编写，商家提供了mixly程序进行代码编写，由于其示例程序过于复杂，涉及到蓝牙、wifi模块以及无线控制和遥控机控制这些额外的事件循环和监听，为了优化程序结构，加快执行速度，我们只保留了用于串口指令交互的部分相关的代码。

源代码与说明：
```C++
void parse_action(u8 *uart_receive_buf) {
    static unsigned int index, time1, pwm1, pwm2, i, len;//声明三个变量分别用来存储解析后的舵机序号，舵机执行时间，舵机PWM
    if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == '!')) {
        delay(500);
    }
    Serial.println((char *)uart_receive_buf);
    if(zx_read_flag) {
  	  //#001P1500! 回读处理
  	  if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[9] == '!')) {
    	    index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
			  if(index == zx_read_id) {
 				  zx_read_flag = 0;
      		  zx_read_value = (uart_receive_buf[5]-'0')*1000 + (uart_receive_buf[6]-'0')*100 +  (uart_receive_buf[7]-'0')*10 +  (uart_receive_buf[8]-'0');
			  }
		}
    //#001PSCK+100! 偏差处理
    } else if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == 'S') && (uart_receive_buf[6] == 'C') && (uart_receive_buf[7] == 'K')) {
        index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
        if(index < SERVO_NUM) {
            int bias_tmp = (uart_receive_buf[9]-'0')*100 +  (uart_receive_buf[10]-'0')*10 +  (uart_receive_buf[11]-'0');
            if(bias_tmp < 127) {
            myservo[index].attach(servo_pin[index]);
              if(uart_receive_buf[8] == '+') {
                  servo_do[index].cur = servo_do[index].cur-eeprom_info.dj_bias_pwm[index]+bias_tmp;
                  eeprom_info.dj_bias_pwm[index] = bias_tmp;
              } else if(uart_receive_buf[8] == '-') {
                  servo_do[index].cur = servo_do[index].cur-eeprom_info.dj_bias_pwm[index]-bias_tmp;
                  eeprom_info.dj_bias_pwm[index] = -bias_tmp;
              }
              rewrite_eeprom();
				servo_do[index].cur = 1500;
				servo_do[index].aim = 1500+eeprom_info.dj_bias_pwm[index]; //舵机PWM赋值,加上偏差的值
				servo_do[index].time1 = 100;      //舵机执行时间赋值
				servo_do[index].inc = eeprom_info.dj_bias_pwm[index]/5.000; //根据时间计算舵机PWM增量
              //Serial.print("input bias:");
              //Serial.println(eeprom_info.dj_bias_pwm[index]);
           }
        }
    //停止处理
    } else if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == 'D') && (uart_receive_buf[6] == 'S') && (uart_receive_buf[7] == 'T')) {
        index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
        if(index < SERVO_NUM) {
              servo_do[index].inc =  0.001;
              servo_do[index].aim = servo_do[index].cur;
        }
    } else if((uart_receive_buf[0] == '#') || (uart_receive_buf[0] == '{')) {   //解析以“#”或者以“{”开头的指令
        len = strlen(uart_receive_buf);     //获取串口接收数据的长度
        index=0; pwm1=0; time1=0;           //3个参数初始化
        for(i = 0; i < len; i++) {          //
            if(uart_receive_buf[i] == '#') {        //判断是否为起始符“#”
                i++;                        //下一个字符
                while((uart_receive_buf[i] != 'P') && (i<len)) {     //判断是否为#之后P之前的数字字符
                    index = index*10 + (uart_receive_buf[i] - '0');  //记录P之前的数字
                    i++;
                }
                i--;                          //因为上面i多自增一次，所以要减去1个
            } else if(uart_receive_buf[i] == 'P') {   //检测是否为“P”
                i++;
                while((uart_receive_buf[i] != 'T') && (i<len)) {  //检测P之后T之前的数字字符并保存
                    pwm1 = pwm1*10 + (uart_receive_buf[i] - '0');
                    i++;
                }
                i--;
            } else if(uart_receive_buf[i] == 'T') {  //判断是否为“T”
                i++;
                while((uart_receive_buf[i] != '!') && (i<len)) {//检测T之后!之前的数字字符并保存
                    time1 = time1*10 + (uart_receive_buf[i] - '0'); //将T后面的数字保存
                    i++;
                }
                if(time1<SERVO_TIME_PERIOD)time1=SERVO_TIME_PERIOD;//很重要，防止被除数为0
                if((index == 255) && (pwm1 >= 500) && (pwm1 <= 2500) && (time1<10000)) {  //如果舵机号和PWM数值超出约定值则跳出不处理
						for(int i=0;i<SERVO_NUM;i++) {
                    		pwm2 = pwm1+eeprom_info.dj_bias_pwm[i];
                    		if(pwm2 > 2500)pwm2 = 2500;
                    		if(pwm2 < 500)pwm2 = 500;
                    		servo_do[i].aim = pwm2; //舵机PWM赋值,加上偏差的值
                    		servo_do[i].time1 = time1;      //舵机执行时间赋值
                    		float pwm_err = servo_do[i].aim - servo_do[i].cur;
                    		servo_do[i].inc = (pwm_err*1.00)/(time1/SERVO_TIME_PERIOD); //根据时间计算舵机PWM增量
						}
                } else if((index >= SERVO_NUM) || (pwm1 > 2500) ||(pwm1 < 500)|| (time1>10000)) {  //如果舵机号和PWM数值超出约定值则跳出不处理
                } else {
                    servo_do[index].aim = pwm1+eeprom_info.dj_bias_pwm[index];; //舵机PWM赋值,加上偏差的值
                    if(servo_do[index].aim > 2500)servo_do[index].aim = 2500;
                    if(servo_do[index].aim < 500)servo_do[index].aim = 500;
                    servo_do[index].time1 = time1;      //舵机执行时间赋值
                    float pwm_err = servo_do[index].aim - servo_do[index].cur;
                    servo_do[index].inc = (pwm_err*1.00)/(time1/SERVO_TIME_PERIOD); //根据时间计算舵机PWM增量
                }
                index = pwm1 = time1 = 0;
            }
        }
    }
}
```

这个函数用于解析串口接收的字符串，其中定义了三个关键变量：index、time1、pwm1、pwm2，他们分别代表舵机索引、执行周期和传入的舵机pwm值，加上偏差之后的pwm值。

参数为unit_8类型的指针，指向指令值存放的地址。

```python
if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == '!')) {
        delay(500);
    }
```
定义接受到形如`#001P!`的指令会暂停500毫秒再执行。

**回读处理：**

```C
if(zx_read_flag) {
  	  //#001P1500! 回读处理
  	  if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[9] == '!')) {
    	    index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
			  if(index == zx_read_id) {
 				  zx_read_flag = 0;
      		  zx_read_value = (uart_receive_buf[5]-'0')*1000 + (uart_receive_buf[6]-'0')*100 +  (uart_receive_buf[7]-'0')*10 +  (uart_receive_buf[8]-'0');
			  }
		}
```

回读操作，如果存在回读标记则进行回读处理，在回读处理中检查指令格式是否正确，如果指令格式正确则通过指令中索引为1、2、3的字符确定舵机的索引号，这里的123字符指舵机的ID。
如果索引等于回读的舵机索引，则将回读标记改为0，将回读的值储存，内容和指令的第5678索引位的字符计算出的值。


变量说明：

| 变量名              | 类型           | 说明                 |
| ---------------- | ------------ | ------------------ |
| zx_read_flag     | int          | 指示是否已读标记，0为已读、1为未读 |
| uart_receive_buf | \*unit8      | 指向串口指令的unit8指针     |
| index            | unsigned int | 舵机索引               |
| zx_read_id       | int          | 回读舵机索引             |
| zx_read_value    | int          | 回读指令PWM 值          |

**偏差处理：**

```c
else if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == 'S') && (uart_receive_buf[6] == 'C') && (uart_receive_buf[7] == 'K')) {
        index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
        if(index < SERVO_NUM) {
            int bias_tmp = (uart_receive_buf[9]-'0')*100 +  (uart_receive_buf[10]-'0')*10 +  (uart_receive_buf[11]-'0');
            if(bias_tmp < 127) {
            myservo[index].attach(servo_pin[index]);
              if(uart_receive_buf[8] == '+') {
                  servo_do[index].cur = servo_do[index].cur-eeprom_info.dj_bias_pwm[index]+bias_tmp;
                  eeprom_info.dj_bias_pwm[index] = bias_tmp;
              } else if(uart_receive_buf[8] == '-') {
                  servo_do[index].cur = servo_do[index].cur-eeprom_info.dj_bias_pwm[index]-bias_tmp;
                  eeprom_info.dj_bias_pwm[index] = -bias_tmp;
              }
              rewrite_eeprom();
				servo_do[index].cur = 1500;
				servo_do[index].aim = 1500+eeprom_info.dj_bias_pwm[index]; //舵机PWM赋值,加上偏差的值
				servo_do[index].time1 = 100;      //舵机执行时间赋值
				servo_do[index].inc = eeprom_info.dj_bias_pwm[index]/5.000; //根据时间计算舵机PWM增量
              //Serial.print("input bias:");
              //Serial.println(eeprom_info.dj_bias_pwm[index]);
           }
        }
    //停止处理
    }
```

在偏差处理的片段由一个条件判断开始，这里条件判断的意义是当串口指令满足形如 _!000PSCK+100_或者 _！000PSCK-100_ 格式时执行此动作。  
指令中 000代表舵机编号，+-100指在当前的舵机默认的PWM值上加减的误差值。  
偏差处理用于解决 当舵机安装的初始角度不正确时，可以通过偏差处理来调整默认的舵机角度以达到在舵机启动初始化和调整舵机pwm值时能够使舵机的运动基于舵机角度处于中心时的pwm值调整。

变量说明：

|变量名|类型|说明|
|:-:|:-:|:-:|
|uart_receive_buf|*u8|指向串口接收指令的值的指针|
|bias_tmp|int|临时储存偏差值的变量|
|myservo|Servo|舵机类的对象|
|servo_do|struct duoji_struct|舵机数据结构体：  <br>unsigned int aim-舵机目标值  <br>float cur-舵机当前值  <br>unsigned int time1-舵机执行时间  <br>float inc-舵机值增量|
|eeprom_info|struct eeprom_info_t|储存器结构体：|
|||long myversion-当前版本|
|||long dj_record_num-未引用，无意义  <br>byte pre_cmd-预执行指令  <br>int dj_bias_pwm-舵机当前pwm偏差值|

**停止处理**

```C++
else if((uart_receive_buf[0] == '#') && (uart_receive_buf[4] == 'P') && (uart_receive_buf[5] == 'D') && (uart_receive_buf[6] == 'S') && (uart_receive_buf[7] == 'T')) {
        index = (uart_receive_buf[1]-'0')*100 +  (uart_receive_buf[2]-'0')*10 +  (uart_receive_buf[3]-'0');
        if(index < SERVO_NUM) {
              servo_do[index].inc =  0.001;
              servo_do[index].aim = servo_do[index].cur;
        }
}
```

停止处理对应的舵机指令格式为：

```
#舵机IDPDST
```

例如#001PDST指令使1号舵机停止运动。

逻辑是首先是进行指令判断，然后判断舵机索引，如果计算得出的舵机索引小于舵机数量，则此舵机存在，将他的增量调整为0.001并且把目标pwm值调整为当前值，即停止运动。

**运动处理**：

运动处理是整个指令系统的核心部分，代码片段：

```C++
else if((uart_receive_buf[0] == '#') || (uart_receive_buf[0] == '{')) {   //解析以“#”或者以“{”开头的指令
        len = strlen(uart_receive_buf);     //获取串口接收数据的长度
        index=0; pwm1=0; time1=0;           //3个参数初始化
        for(i = 0; i < len; i++) {          //
            if(uart_receive_buf[i] == '#') {        //判断是否为起始符“#”
                i++;                        //下一个字符
                while((uart_receive_buf[i] != 'P') && (i<len)) {     //判断是否为#之后P之前的数字字符
                    index = index*10 + (uart_receive_buf[i] - '0');  //记录P之前的数字
                    i++;
                }
                i--;                          //因为上面i多自增一次，所以要减去1个
            } else if(uart_receive_buf[i] == 'P') {   //检测是否为“P”
                i++;
                while((uart_receive_buf[i] != 'T') && (i<len)) {  //检测P之后T之前的数字字符并保存
                    pwm1 = pwm1*10 + (uart_receive_buf[i] - '0');
                    i++;
                }
                i--;
            } else if(uart_receive_buf[i] == 'T') {  //判断是否为“T”
                i++;
                while((uart_receive_buf[i] != '!') && (i<len)) {//检测T之后!之前的数字字符并保存
                    time1 = time1*10 + (uart_receive_buf[i] - '0'); //将T后面的数字保存
                    i++;
                }
                if(time1<SERVO_TIME_PERIOD)time1=SERVO_TIME_PERIOD;//很重要，防止被除数为0
                if((index == 255) && (pwm1 >= 500) && (pwm1 <= 2500) && (time1<10000)) {  //如果舵机号和PWM数值超出约定值则跳出不处理
						for(int i=0;i<SERVO_NUM;i++) {
                    		pwm2 = pwm1+eeprom_info.dj_bias_pwm[i];
                    		if(pwm2 > 2500)pwm2 = 2500;
                    		if(pwm2 < 500)pwm2 = 500;
                    		servo_do[i].aim = pwm2; //舵机PWM赋值,加上偏差的值
                    		servo_do[i].time1 = time1;      //舵机执行时间赋值
                    		float pwm_err = servo_do[i].aim - servo_do[i].cur;
                    		servo_do[i].inc = (pwm_err*1.00)/(time1/SERVO_TIME_PERIOD); //根据时间计算舵机PWM增量
						}
                } else if((index >= SERVO_NUM) || (pwm1 > 2500) ||(pwm1 < 500)|| (time1>10000)) {  //如果舵机号和PWM数值超出约定值则跳出不处理
                } else {
                    servo_do[index].aim = pwm1+eeprom_info.dj_bias_pwm[index];; //舵机PWM赋值,加上偏差的值
                    if(servo_do[index].aim > 2500)servo_do[index].aim = 2500;
                    if(servo_do[index].aim < 500)servo_do[index].aim = 500;
                    servo_do[index].time1 = time1;      //舵机执行时间赋值
                    float pwm_err = servo_do[index].aim - servo_do[index].cur;
                    servo_do[index].inc = (pwm_err*1.00)/(time1/SERVO_TIME_PERIOD); //根据时间计算舵机PWM增量
                }
                index = pwm1 = time1 = 0;
            }
        }
    }
```

这里是解析运控指令的部分，整体执行的条件是指令满足以 **#** 或者 **{** 开头，即运动部分的指令应当是由#开头的单个指令或者是由{}包裹的组合指令。

初始化参数解释：

|变量名|类型|说明|
|:-:|:-:|:--|
|len|int|指令长度|
|index|int|舵机索引|
|pwm1|int|指定舵机的pwm值|
|time1|int|动作执行周期|
|i|int|指令的字节索引|

主循环的条件是指令的字节索引小于指令的长度。

**指令解析过程：** 循环体内根据指令的字节索引对应的值来判断执行的指令，首先是在索引中判断到#字符则认为是一段指令的开始，随后的三位是舵机的ID，第四位为固定值P，随后的所有字符直到T之前的字符被认为是要调整的舵机PWM值。当字符为T时，检测T之后!之前的数值，并将其保存到time1变量中，这些字符为舵机从当前的PWM值调整到新的PWM值所消耗的时间。  
最后以!结尾，当检测到!时一条指令结束，随后进行第二条指令的判断，即从上述指令解析过程重新开始。

由此可得，运动控制的指令为：

```
{#舵机IDP舵机PWM值T周期!}
```

其中：  
**舵机ID应为三位，不足三位用0补齐。**  
**PMW值应为四位，不足四位用0补齐。**  
**周期应为四位，不足四位用0补齐，周期最大值为9999即9.99秒。**

**串口动作指令**

除上述指令外，还有其他的常用串口通信指令， 所有的指令如下所示：

![小杜的个人图床](http://src.xiaodu0.com/2024/05/19/cb819682deebca673721e5c25e6f6435.png)

![小杜的个人图床](http://src.xiaodu0.com/2024/05/19/d9026067bcdaac0fe9810ea31d437ece.png)

指令解释：

**1、#000P1500T1000!**

解析：“#”和“!”是固定英文格式。000代表ID（范围0-254），必须为 3位，不足补0。比如3号舵机 为“003”而不能为“3”。1500 代表PWM脉冲宽度调制（P）（范围500-2500）， 必须为4位，不足补 0。比如PWM为800，则必须为“P0800”。1000代表TIME时间(T)（范围0-9999），同样必须为 4 位，不足补0，单位ms。比如TIME为500，则必须为“T0500” 该指令可以叠加同时控制多个舵机。多个指令同时使用时（2个或2个以上叠加）需要在整条指令 前后加“{}”，比如：{G0000#000P1602T1000!#001P2500T0000!#002P1500T1000!}

**2、#000PVER!**

解析：读取舵机版本号，返回格式为：#000PV0.97!

**3、#000PID!**

解析：指定ID检测，该指令时读取000的ID，检测当前舵机是否为000 这个ID号，是返回#000P!。 否则无返回，当不知道舵机ID时，发送#255PID! 可返回舵机ID号。

**4、#000PID001!**

解析：指定修改ID，该指令是把000号ID改为001号，修改成功后返回#001P!。不成功无返回。

**5、#000PULK!**

解析：释放后舵机处于制动状态，此时可以用手扳动舵机旋转。在纠正舵机偏差和手动编程时会用 到此功能，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**6、#000PULR!**

解析：恢复扭力，以舵机当前的位置恢复扭力，成功返回#OK!。

**7、#000PMOD!**

解析：读取舵机当前的工作模式，返回如下：  
[#000PMOD1](app://obsidian.md/index.html#000PMOD1)! ：舵机模式，角度最大范围270度，方向顺时针  
[#000PMOD2](app://obsidian.md/index.html#000PMOD2)! ：舵机模式，角度最大范围270度，方向逆时针  
[#000PMOD3](app://obsidian.md/index.html#000PMOD3)! ：舵机模式，角度最大范围180度，方向顺时针  
[#000PMOD4](app://obsidian.md/index.html#000PMOD4)! ：舵机模式，角度最大范围180度，方向逆时针  
[#000PMOD5](app://obsidian.md/index.html#000PMOD5)! ：马达模式，角度360度，定圈旋转，方向顺时针  
[#000PMOD6](app://obsidian.md/index.html#000PMOD6)! ：马达模式，角度360度，定圈旋转，方向逆时针  
[#000PMOD7](app://obsidian.md/index.html#000PMOD7)! ：马达模式，角度360度，定时旋转，方向顺时针  
[#000PMOD8](app://obsidian.md/index.html#000PMOD8)! ：马达模式，角度360度，定时旋转，方向逆时针

**8、#000PMOD1!**

解析：设置舵机工作模式，默认工作模式为1  
1：舵机模式 270度顺时针  
2：舵机模式 270度逆时针  
3：舵机模式 180度顺时针  
4：舵机模式 180度逆时针  
5：马达模式 360度定圈顺时针模式  
6：马达模式 360度定圈逆时针模式  
7：马达模式 360度定时顺时针模式  
8：马达模式 360度定时逆时针模式  
**设置成功均返回#OK!**

关于定圈定时问题解释：  
定圈模式：若指令为 [#000P1800T1000](app://obsidian.md/index.html#000P1800T1000)! 表示以300（1800-1500）的速度，运行1000圈后停 止，允许误差存在。若T=0000！ 则表示以300（1800-1500）的速度无限循环执行。  
定时模式：若指令为 [#000P1800T1000](app://obsidian.md/index.html#000P1800T1000)! 表示以300（1800-1500）的速度，运行1000S后停止， 允许误差存在。若T=0000！ 则表示以300（1800-1500）的速度无限循环执行。

**9、#000PRAD!**  
解析：读取舵机当前位置，返回格式为#000P1500!。

**10、#000PDPT!**

解析：暂停，舵机运行过程中接收此指令，会停止当前，再接收继续指令后，会接在当前位置继续 运行，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**11、#000PDCT!**  
解析：配合暂停指令继续操作，比如#001P2500T5000! 发送给舵机，在2000ms的时候发送了 [#000PDPT](app://obsidian.md/index.html#000PDPT)! 指令给舵机，则舵机暂停，保持力矩在停止的位置，再发送#000PDCT!给舵机，则舵 机继续剩余的3000ms结束，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**12、#000PDST!**  
解析：停止在当前位置，与暂停指令不同的事，之后无法继续执行，需重新执行，返回#OK!。

**13、#000PBD1!**  
解析：设置舵机通信波特率，默认115200。数字参数对应关系为：1-9600，2-19200，3-38400， 4-57600，5-115200，6-128000，7-256000，8-1000000，该指令设置成功后返回#000PBD9600!。

**14、#000PSCK!**  
解析：用于纠正偏差，将当前位置设置为1500中间值，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**15、#000PCSD!**  
解析：设置舵机启动位置，默认1500，开机自启动范围为0500~2500，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**16、#000PCSM!**  
解析：去除初始值，使用该命令后，#000PCSD! 指令失效，舵机启动释力状态。成功返回 [#OK](app://obsidian.md/index.html#OK)!。

17、#000PCSR!  
解析：恢复初始值，使用该命令后，舵机启动恢复力矩，#000PCSD! 指令恢复，转到初始值，成功 返回 [#OK](app://obsidian.md/index.html#OK)!。

18、#000PSMI!  
解析：设置舵机最小值，最小值默认为0500，将舵机调节到合适位置后，发送此命令设置。 成功 返回#OK!。

**19、#000PSMX!**  
解析：设置舵机最大值，最大值默认为2500，将舵机调节到合适位置后，发送此命令设置。成功返 回#OK!。

**20、#000PCLE!**  
解析：全恢复出厂设置，ID号恢复000，舵机模式默认1、波特率默认115200、初始值1500、矫正 值1500、最小值0500、最大值2500，成功返回 [#OK](app://obsidian.md/index.html#OK)!。

**21、#000PRTV!**  
解析：获取温度和电压，成功返回 [#000T25V07](app://obsidian.md/index.html#000T25V07)!

**22、#000PSTB!**  
解析：读取设置温度和电压。

**23、#000PSTB=60!**  
解析：设置释放扭力阈值温度为60


**常用动作指令**：

| 指令                                                             | 说明            |
| -------------------------------------------------------------- | ------------- |
| {#001P1200T1000!#002P1900T1000!#003P1100T1000!#005P1000T2000!} | 向开发板方向抓取      |
| {#001P1200T2000!#002P1900T2000!#003P1100T2000!#005P1500T3000!} | 向开发板方向放置      |
| {#001P1500T1000!#002P1500T1000!#003P1500T1000!}                | 回正为垂直状态（爪子不动） |
| {#001P1500T1000!#002P1500T1000!#003P1500T1000!#005P1500T1000!} | 回正为垂直状态（爪子张开） |


### (2).串口通信程序设计

由于我们整个系统的控制代码是使用Python实现的， 因此在将C++的逻辑代码烧录到机械臂核心的Arduino控制主板之后，通过Python封装一系列串口通信的代码的动作指令供运动控制程序交互调用。

Arduino单片机的上位机串口通讯要首先安装CH340驱动程序：

```bash
sudo apt-get install git 
git clone https://github.com/juliagoda/CH341SER.git 
cd CH341SER 
make 
sudo make load
```

安装完成之后，再安装Python需要的相关依赖：

```
pySerial
time
```

将机械臂连接到机械狗之后，通过Python获取端口信息：

```python
#coding=UTF-8
import serial
import serial.tools.list_ports
import time
def getPorts():
    ports_list = list(serial.tools.list_ports.comports())
    if len(ports_list) <= 0:
        print("无串口设备。")
    else:
        print("可用的串口设备如下：")
        for comport in ports_list:
            print(list(comport)[0], list(comport)[1])
  
getPorts()
```

输出：

```
可用的串口设备如下：
('/dev/ttyUSB4', 'USB Serial')
('/dev/ttyUSB3', 'EG25-G')
('/dev/ttyUSB2', 'EG25-G')
('/dev/ttyUSB1', 'EG25-G')
('/dev/ttyUSB0', 'EG25-G')
('/dev/ttyAMA0', 'ttyAMA0')
```

其中USB Serial即为串口USB端口，也就是机械臂连接的USB端口。

测试发送指令：

```python
ser = serial.Serial(port="/dev/ttyUSB4", baudrate=115200, timeout=1)

ser.write(b"{#000P1000T1000!#001P1200T1000!#002P1900T1000!#003P1100T1000!#005P1000T2000!}")

time.sleep(5)

ser.write(b"{#001P1500T1000!#002P1500T1000!#003P1500T1000!}")
```

实际运行表示良好。

### (3).交互程序封装

在主函数中封装了获取端口与发送指令的程序：
```python
import time  
import serial  
import serial.tools.list_ports  
import action  
def getPorts():  
    ports_list = list(serial.tools.list_ports.comports())  
    if len(ports_list) <= 0:  
        print("无串口设备。")  
    else:  
        print("可用的串口设备如下：")  
        for comport in ports_list:  
            print(list(comport)[0], list(comport)[1])  
  
def doAction(actions):  
    for action in actions:  
        ser.write(b"%s"%action['commend'])  
        time.sleep(action['delay'])  
  
ser = serial.Serial(port="COM11", baudrate=115200, timeout=1)  
doAction(action.init)  
doAction(action.craw)  
doAction(action.stand)  
# ser.write(b"#005P1500T1000!")  
getPorts()
```

`doAction`方法根据给定的指令序列执行动作，预定义的指令序列如下：
```python
"""  
物料编号：  
0 - 正方体  
1 - 圆柱体  
2 - 三棱锥  
3 - 半球  
  
舵机方向说明：  
- 以开发板方向为前方，也就是狗头方向  
0号舵机：正左负右  
1号舵机：正后负前  
2号舵机：正后负前  
3号舵机：正前负后  
4号舵机：正左负右  
5号舵机：正大负小  
  
第一个倾倒区的放左边  
第二个倾倒区的放右边  
"""  
  
action = {  
    "init": [  
        {  
            "commend": b"#000P1500T1000!",  
            "delay": 0  
        },  
        {  
            "commend": b"#001P1500T1000!",  
            "delay": 0  
        },  
        {  
            "commend": b"#002P1500T1000!",  
            "delay": 0.5  
        },  
        {  
            "commend": b"#003P1500T1000!",  
            "delay": 0  
        },  
        {  
            "commend": b"#004P1500T1000!",  
            "delay": 0  
        },  
        {  
            # "time":500,  
            "commend": b"#005P1500T1000!",  
            "delay": 2  
        },  
    ],  
    "stand": [  
        {  
            "commend": b"#001P1500T2000!",  
            "delay": 2  
        },  
        {  
            "commend": b"#002P1500T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#003P1500T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#004P1500T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#005P0800T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#000P1500T1000!",  
            "delay": 1  
        }  
    ],  
    "craw": [  
        {  
            "commend": b"#003P1600T1000!",  
            "delay": 0.5  
        },  
        {  
            "commend": b"#001P1300T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#002P1200T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#003P1800T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#005P0900T1000!",  
            "delay": 1  
        }  
    ],  
    "craw_to_left": [  
        {  
            "commend": b"#000P2300T2000!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#001P0800T2500!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#002P1200T2000!",  
            "delay": 1.5  
        },  
        {  
            "commend": b"#003P1600T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#004P1500T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#005P0500T2000!",  
            "delay": 3  
        },  
    ],  
    "drop_to_left": [  
        {  
            "commend": b"#001P1620T2500!",  
            "delay": 3  
        },  
        {  
            "commend": b"#002P1800T2000!",  
            "delay": 1.5  
        },  
        {  
            "commend": b"#000P1300T2000!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#003P0700T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#004P1500T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#005P1500T2000!",  
            "delay": 3  
        },  
    ],  
    "craw_to_right": [  
        {  
            "commend": b"#000P0700T2000!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#001P0800T2500!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#002P1200T2000!",  
            "delay": 1.5  
        },  
        {  
            "commend": b"#003P1600T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#004P1500T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#005P0500T2000!",  
            "delay": 3  
        },  
    ],  
    "drop_to_right":  
        [  
  
            {  
                "commend": b"#001P1620T2500!",  
                "delay": 2.5  
            },  
            {  
                "commend": b"#002P1800T2000!",  
                "delay": 1.5  
            },  
            {  
                "commend": b"#000P1700T2000!",  
                "delay": 2.5  
            },  
            {  
                "commend": b"#003P0700T1000!",  
                "delay": 1.2  
            },  
            {  
                "commend": b"#004P1500T1000!",  
                "delay": 1.2  
            },  
            {  
                "commend": b"#005P1500T2000!",  
                "delay": 3  
            },  
        ],  
    "drop_from_right": [  
        {  
            "commend": b"#005P1347T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#000P1711T2000!",  
            "delay": 2.5  
        },  
        {  
            "commend": b"#001P1270T1000!",  
            "delay": 1  
        },  
        {  
            "commend": b"#003P1180T2000!",  
            "delay": 2  
        },  
        {  
            "commend": b"#002P2335T3000!",  
            "delay": 3  
        },  
        {  
            "commend": b"#004P1660T1000!",  
            "delay": 1.2  
        },  
        {  
            "commend": b"#005P0600T2000!",  
            "delay": 3  
        },  
    ]  
}  
  
action_group = {  
    "group_craw_to_right": b"{#000P2300T1000!#001P0900T1500!#002P1150T1000!#003P1600T1000!#004P1500T1000!#005P900T1000!}"  
  
}```

action.py中包含两个全局变量，其中action储存按周期执行的单个动作组合，他的类型是一个字段，字段中的键值对是动作名和对应执行的指令，指令的数据烈性也是字典，包含每个动作的指令和延时周期，动作字典中的`commend`键为对应的串口指令，`delay`键为执行此指令之后暂停的时间。
采用延迟是为了防止当前动作还未执行完就执行下一个动作而产生预料之外的情况。

在机器人的运控板中上传此示例程序，通过python3执行即可实现交互，但是仍然有需要优化的地方，在控制时调用程序执行固定的动作显然不是一个好的方法，于是我们将其通过`argparse`库封装为shell程序，使其可以通过shell 调用并且指定相关参数。

```python
import time
import serial
import serial.tools.list_ports
import argparse
import action

def getPorts():
    """
    列出所有可用的串口设备。
    """
    ports_list = list(serial.tools.list_ports.comports())
    if len(ports_list) <= 0:
        print("无串口设备。")
    else:
        print("可用的串口设备如下：")
        for comport in ports_list:
            print(list(comport)[0], list(comport)[1])

def doAction(actions, ser):
    """
    执行一系列动作命令。
    
    参数:
    actions: 动作列表，每个动作包含 'commend' 和 'delay'。
    ser: 串口对象。
    """
    for action in actions:
        ser.write(b"%s" % action['commend'])
        time.sleep(action['delay'])

def main():
    """
    主函数，解析命令行参数并执行相应动作。
    """
    parser = argparse.ArgumentParser(description="串口动作控制程序")
    parser.add_argument("--port", type=str, required=True, help="串口端口，例如 COM11")
    parser.add_argument("--baudrate", type=int, default=115200, help="波特率，默认 115200")
    parser.add_argument("--timeout", type=int, default=1, help="串口超时时间，默认 1 秒")
    parser.add_argument("--P", type=str, help="P 参数")
    parser.add_argument("--T", type=str, help="T 参数")
    parser.add_argument("--action", type=str, required=True, choices=['init', 'craw', 'stand'], help="要执行的动作")

    args = parser.parse_args()

    try:
        ser = serial.Serial(port=args.port, baudrate=args.baudrate, timeout=args.timeout)
        print(f"已连接到串口 {args.port}，波特率 {args.baudrate}")

        actions = getattr(action, args.action)
        doAction(actions, ser)

        if args.P and args.T:
            command = f"#{args.P}P{args.T}!"
            ser.write(command.encode())
            print(f"发送命令: {command}")

        getPorts()

    except serial.SerialException as e:
        print(f"无法连接到串口 {args.port}: {e}")
    finally:
        if 'ser' in locals() and ser.is_open:
            ser.close()
            print(f"已关闭串口 {args.port}")

if __name__ == "__main__":
    main()

```

在优化之后，可以通过shell调用此程序来实现执行相关动作、指定端口、波特率、P参数（pwm值）和T值（执行时间）。
相关解释如下：

`getPorts()`
列出所有可用的串口设备。

`doAction(actions, ser)`
执行一系列动作命令。
- **参数**:
    - `actions`: 动作列表，每个动作包含 `commend` 和 `delay`。
    - `ser`: 串口对象。

 `main()`
主函数，解析命令行参数并执行相应动作。
- **参数**:
    - `--port`: 串口端口，例如 `COM11`。
    - `--baudrate`: 波特率，默认 `115200`。
    - `--timeout`: 串口超时时间，默认 `1` 秒。
    - `--P`: P 参数。
    - `--T`: T 参数。
    - `--action`: 要执行的动作（`init`、`craw` 或 `stand`）。

在机器人中，通过深度相机获取点云图数据来计算物体的相对位置，并且将其转换为机械臂的控制参数，调用控制程序来实现物体的抓取。

```python
import subprocess
import cv2
import pcl
import numpy as np

def get_point_cloud(depth_image, camera_intrinsics):
    """
    根据深度图像和相机内参生成点云图。
    
    参数:
    depth_image: 深度图像。
    camera_intrinsics: 相机内参矩阵。
    
    返回:
    point_cloud: 生成的点云图。
    """
    height, width = depth_image.shape
    fx, fy = camera_intrinsics[0, 0], camera_intrinsics[1, 1]
    cx, cy = camera_intrinsics[0, 2], camera_intrinsics[1, 2]
    
    points = []
    for v in range(height):
        for u in range(width):
            z = depth_image[v, u] / 1000.0
            if z == 0:
                continue
            x = (u - cx) * z / fx
            y = (v - cy) * z / fy
            points.append([x, y, z])
    
    point_cloud = pcl.PointCloud(np.array(points, dtype=np.float32))
    return point_cloud

def extract_object_position(point_cloud):
    """
    从点云图中提取物体位置。
    
    参数:
    point_cloud: 点云图。
    
    返回:
    (x, y, z): 物体在相机坐标系中的位置。
    """
    # 假设物体是点云中最大的簇
    seg = point_cloud.make_EuclideanClusterExtraction()
    seg.set_ClusterTolerance(0.02)
    seg.set_MinClusterSize(100)
    seg.set_MaxClusterSize(25000)
    clusters = seg.Extract()
    
    largest_cluster = clusters[0]
    object_points = point_cloud.extract(largest_cluster)
    centroid = np.mean(object_points.to_array(), axis=0)
    return centroid

def calculate_grasp_parameters(position):
    """
    根据物体位置计算机械臂抓取所需的控制参数。
    
    参数:
    position: 物体位置 (x, y, z)。
    
    返回:
    P: 抓取位置参数
    T: 抓取时间参数
    """
    x, y, z = position
    P = f"{x + y:.2f}"
    T = f"{z:.2f}"
    return P, T

def main():
    # 假设已经获取到深度图像和相机内参
    depth_image = cv2.imread('depth_image.png', cv2.IMREAD_UNCHANGED)
    camera_intrinsics = np.array([[525.0, 0.0, 319.5],
                                  [0.0, 525.0, 239.5],
                                  [0.0, 0.0, 1.0]])
    
    point_cloud = get_point_cloud(depth_image, camera_intrinsics)
    position = extract_object_position(point_cloud)
    P, T = calculate_grasp_parameters(position)
    
    port = "COM11"
    baudrate = 115200
    action = "craw"
    
    subprocess.run([
        "python", "serial_control.py",
        "--port", port,
        "--baudrate", str(baudrate),
        "--action", action,
        "--P", P,
        "--T", T
    ])

if __name__ == "__main__":
    main()

```


其中：
- **`get_point_cloud(depth_image, camera_intrinsics)`**：将深度图像和相机内参转换为点云图。
- **`extract_object_position(point_cloud)`**：从点云图中提取物体的位置。假设物体是点云中最大的簇。
- **`calculate_grasp_parameters(position)`**：根据物体位置计算机械臂的控制参数`P`和`T`。
- **`main()`**：
    - 获取深度图像和相机内参。
    - 生成点云图并提取物体位置。
    - 计算抓取参数并调用`serial_control.py`脚本执行抓取动作。



# Part II 机器人设计

## 1. 问题分析 

在设计机器人实现指定任务之前，首先需要明确作品需要解决什么问题。

首先，根据赛程规则，我们主要需要实现的部分是：
1. 自动循迹驾驶走完赛道。
2. 注意环岛和十字路口以及双岔路口，选择合适的路径。
3. 在环岛中心倾倒物资。
4. 在启停区完成启动和停止。
5. 协调机械臂完成物资的识别与抓取。
6. 实现机器人的避障，识别到障碍物后执行避障逻辑。

其中机械臂与机器人交互的部分在title #3 Part I 部分已经说明，这里只做简单的阐述。

### (1). 机械臂与机器人的交互

机器人与机器臂交互部分，涉及的主要问题是机器人与机械臂如何交互？在交互过程中需要传递哪些数据，以及整个交互的流程。

由于物资抓取是在比赛开始之前，所以在机器人上场行走之前就要完成物资的抓取工作，因此设计了机械臂抓取物资动作的程序，通过PC连接到机器人，启动程序机器人即通过串口发送数据来控制机械臂抓取物资，也就是，抓取物资的实现是通过串口通信的方式实现的。

交互过程中，由机器人的深度相机来获取物资的位置信息，通过位置信息计算出相对位置再计算机械臂各个舵机的PWM值，将PWM和对应的执行时间通过串口发送给机械臂的控制板卡。

整个交互流程是：启动机器人、连接到机械人执行识别与抓取程序、机器人通过串口发送数据、机械臂执行动作。

### (2). 物资识别的实现

物资识别仍然是在机器人的系统中实现的，我们通过opencv来实现物资的识别，物资有四种：圆柱体、三棱锥、正方体、半球。

要实现物资识别，首先通过opencv获取图像，然后通过颜色识别和形状识别来确定物体的形状。

我们使用颜色过滤以及形状检测来确定物资，以顶点的数量的划分物体形状：
- **三棱锥**：检测到3个顶点。
- **正方体**：检测到4个顶点，并且长宽比接近1。
- **圆柱体**：检测到4个顶点，但长宽比不接近1。
- **半球**：检测到超过8个顶点的圆形轮廓。

由于我们将主要的业务都放在14板卡上进行，因此在最开始的物料识别和抓取部分也是通过14板卡对应的侧面摄像头实现的。通过获取侧面摄像头的画面，对物料进行检测，识别对应的物料形状进行抓取。

### (3). 启动与停止

启动与停止依赖于运动SDK与颜色识别实现，首先是启动部分，我们的整体程序是多线程实现的，由于启动在整个流程的开始阶段，停止在结束阶段，因此在启动阶段我们通过在主线程中给定一个固定的左右偏移量使机器人运动到赛道中，这一部分在整个程序的启动时，控制线程初始化之前。

当机器人完整走完全程之后，我们在启停区的后方粘贴一个ID为0的aruco tag，当机器人识别到此tag之后，停止运动线程，执行最后的回到启动区的动作，然后趴下并关机。

### (4). 自动循迹

#### a. ROS与LCM

自动循迹是整个流程中最基础、最重要的阶段，这一部分我们考虑了非常多的方案，首先考虑了通过ROS结合LCM的方式实现，这一想法的具体内容是：
通过在终端与PC之间建立连接，编写键盘控制程序，通过PC键盘来操作机器人完成整个脸赛道流程，将ROS信号利用”convert.h”转换成真正的控制代码，然后结合LCM将转换后的CMD结构体进行保存，并再次复现。

但是在经过多次测试，这种方式实际上仍然是依赖于手动操作，无非是在外在看起来是由自动部分，并且最严重的问题是由于操作手的失误、每一次运行的状况、舵机的转速等等一些列因素，机器人始终无法准确的复现操作流程，于是我们决定放弃这种方式。

随后我们采用计算机视觉的方法进行循迹，根据摄像头实时的处理图像，依据图像数据来确定机器人的位置，并决定接下来如何运动。

#### b. 计算颜色差值运动

首先我们考虑的是通过计算赛道主路线即黄色路线的部分与赛道边缘即白色部分的差值来实现位置控制，首先机器人是恒定速度行走的，然后根据二者的差值水平横移动使图像保持在中间，但是这样做实际上存在很大的风险：机器人总会意料之外的出界，并且导致图像丢失无法继续运动，由于横向移动的误差，机器人无法准确的在赛道中保持在中线位置。

另一方面，这种方式在直道上表现偶尔会良好，但是在遇到弯道时水平移动显然无法解决问题，于是我们又引入了转弯，通过计算白色部分和黄色部分的范围，当白色部分大于黄色部分时，说明机器人即将出界或者到达了转弯处，这时候需要调整角度，这种方法仍然存在一个弊端：当机器人已经出界时再转弯，很容易产生错误的轨迹，进而导致运动无法继续下去。

另一方面，我们考虑计算黄色与白色的中线与整个图像中线的差来纠正位置，但是中线差值转换速度和角度是一个很复杂的过程，并且由于误差的存在，即使我们引入了PID算法也无法完美的解决这个问题，随着多次测试和调试失败，我们最终也决定放弃这个方案。

#### c. 分割图像区域进行计算

分割图像区域是我们的最终方案也是三种方案中效果最好的方案，实际上我们引入了感兴趣的区域的思路，通过将图像分割为三个等份，然后计算每三个图像中黄色部分的中点根据这三个中点的取值，来计算黄色部分的扭曲程度进而确定机器狗需要调整的角度。

这一部分的具体思路是：通过摄像头获取实时视频流，并在图像处理后控制机器人沿着特定路线行驶。感兴趣区域（ROI，Region of Interest）用于在图像中划定特定区域，以便更准确地进行颜色检测和路径规划。

首先，获取视频流并保存到队列中，由于读取和运动控制部分需要分开执行，因此我们通过多线程的方式读取视频帧，将其储存到队列中，并且同时在运动控制线程中读取图像数据。


然后，进行颜色检测与路径规划，我们通过使用颜色阈值（HSV范围）进行颜色检测，识别图像中的黄色区域，并且定义感兴趣的区域，将图像分为上、中、下三个部分，分别检测每个部分的黄色区域，以确定路径方向和转角角度。
最后，根据颜色检测结果和计算的角度，调整机器人速度和转弯角度，实现循迹。

实现分割的结果如图所示：
![小杜的个人图床](http://src.xiaodu0.com/2024/06/30/88c92d6b241524ce8aa69cf5b9de49ef.png)

### (5).环岛和十字路口处理

在完成视觉部分之后，我们考虑确定环岛 的位置，并且执行进入环岛的控制逻辑，在进入环岛之后实现物质的倾倒以及在完成物质倾倒之后驶出环岛。由于我们先前的控制程序包含寻迹的部分，因此在十字路口也能够很妥善的处理，不需要再做额外的代码。

由于环岛同时包含物资的倾倒区了，因此我们通过状态机模型来定义在环岛时不同的动作，在识别到环岛的aruco tag时，系统会将原先的运动主线程挂起，然后执行对应环岛的业务逻辑。

在环岛中首先调整驶入环岛，然后在贴近环岛内部的位置挂起所有运动线程，执行物资倾倒的指令，调用机械臂将物资放置到环岛中。

为了防止在驶出环岛的时候再次执行处理环岛的业务，我们定义了记录四个环岛状态的列表，初始状态都是0，当被检测到之后，开始处理业务逻辑则变为1，在进行环岛业务之前同样判断当颜色对应的环岛是否已经被处理。


### (6).双岔路口处理

在使用视觉循迹开始，双岔路口我们遇到一个问题：当机器人选择一个双岔路口走完之后，又回头走另一个分叉路返航了，经过多次展示摄像头实时数据和标注转角的调试测试之后，我们发现是在机器人刚驶出双岔路之后，两条路合并这时候路线被判定为转向，并且转向角度很大，而实际上这时候虽然要进行转弯到直道的操作，但是转角是比较小的，于是我们通过限制转角，当角度超过60度时则不进行任何操作。

实际表现就是，当机器人识别到双岔路口时，会在刚开始的时候进行转向，当转向角度过大则不进行操作，当机器人驶入双岔路的时候，接着进行正常的循迹。

## 2.技术方案

### (1).整体设计

在整体的技术实现上，我们采用Python语言进行业务开发，结合Unitree_leddeg_sdkV3,8的pythonSDK来设计整体业务。

在省赛的时候，我们使用的循迹部分用到了下巴处的摄像头，因此在头部nano上需要设计摄像头视频流发送程序，起初我们使用的是Gstreamer推流，但是在运动控制板卡安装opencv时没有启用Gstreamer扩展，重新编译安装需要花费太多时间，于是我们考虑换个思路，使用ffmpeg进行推流，但是结果是，由于没有Gstreamer支持，opencv仍然无法正确处理图像帧，导致程序一直报错。

随后考虑到运动控制板卡是树莓派的板子，性能有限并且Opencv编译的时候没有完全启用对应的扩展，因此为了提高系统效率和重新安装完整的opencv，我们转而使用性能更加强悍的Nano板卡来执行核心业务。

在头部板卡正常使用SDK通过Gstreamer打开UDP管道传输图像帧，然后在14板卡上，我们通过Python来读取UDP管道的图像帧，并且拼接完整的图像存放到队列中。

而运动控制部分，则接着由运动控制板卡（树莓派板卡）进行，但是为了三个板卡的合理联动，我们在运动控制板卡上开启一个socket服务端，实时接收14板卡发送的socket消息来控制机器人。

### (2).图像发送部分与接收

优化后的图像发送逻辑非常简单，即通过Opencv打开一个摄像头的实例，然后将从摄像头实时读取数据，将每一个视频帧通过opencv的Gstreamer功能开启UDP管道推流，指定开启的UDP管道对应的IP地址和端口，在接收端通过UDP读取数据，将完整的图像拼接并且存放进队列。

这一部分的重点在于接端拼接并且储存图像。

具体的技术实现是：

整个方案围绕着一个 `Camera` 类来组织，它负责视频流的连接、图像采集和图像的传输。该类允许用户通过指定相机的 ID 来选择特定的摄像头，并通过 UDP 协议获取视频流。采集到的图像会通过队列传递给其他线程或进程进行进一步处理。

`Camera` 类的设计考虑了可扩展性和灵活性。类的初始化方法 `__init__` 支持多个参数配置：

- `cam_id`: 用于指定摄像头的 ID，根据 ID 选择不同的 UDP 端口进行连接。
- `width` 和 `height`: 设定图像的分辨率。
- `frame_queue`: 一个图像帧队列，如果没有传入则创建一个新的队列。该队列用于在多线程环境中传递采集到的图像帧。


`Camera` 类的 `run` 方法是用于持续采集图像并将其放入队列中的主循环：

- 首先，通过 `self.get_img()` 方法初始化摄像头并打开视频流。
- 然后进入一个循环，持续读取视频帧并对图像进行处理（如调整分辨率、翻转图像等）。
- 图像处理后，帧被放入 `frame_queue` 中，供其他线程使用。这种设计使得图像采集与后续处理可以并行进行，提高了系统的实时性和响应速度。

为了保证图像采集的实时性，方案采用了多线程设计。`Camera` 类运行在一个单独的线程中，负责不断采集图像并放入队列，而图像处理和运动控制线程则可以通过图像队列实时进行操作。

### (3).使用ws控制机器人

为了便于使用SDK在内网与主控板通信实现运动控制，我们在运动控制板卡创建了一个websocket服务器，首先导入所需的库：socket、threading和json。其中，socket库用于网络通信，threading库用于多线程处理，json库用于解析JSON格式的数据。然后创建一个名为unitree_robot的Unitree_Robot_High对象，用于控制机器人。
然后定义一个名为client的类，用于表示客户端连接。这个类包含以下方法：
    - **init**：初始化客户端对象，包括地址、端口、用户名和套接字。
    - send：向客户端发送消息。
    - recv：从客户端接收消息，如果接收失败则返回False。
    - close：关闭客户端套接字。
    - id：返回客户端的唯一标识符，即地址和端口的组合。
接着定义一个名为new_client的函数，用于处理客户端连接。这个函数会不断接收客户端发送的命令，并将其解析为JSON格式。然后，根据解析出的命令调用unitree_robot对象的execute方法来控制机器人。如果在处理过程中出现异常，函数会捕获异常并输出错误信息。最后，关闭客户端连接并从客户端列表中移除该客户端。
创建一个socket对象s，绑定到指定的IP地址和端口，并开始监听连接请求。
使用一个无限循环来接受新的客户端连接。每当有新的连接请求时，创建一个新的client对象，并将其添加到客户端列表中。然后，为每个新客户端启动一个新的线程来处理其请求。


我们在14板卡定义了一个名为 `RobotConnector` 的类，用于与服务端建立连接并发送控制指令：
首先，定义一个名为 `RobotConnector` 的类。
在类的构造函数，接收两个参数 `ip_address` 和 `port`，分别表示机器人的 IP 地址和端口号。默认值分别为 `192.168.123.161` 和 `8000`。
然后创建一个元组 `address_server`，包含 IP 地址和端口号。
通过`self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)`：创建一个套接字对象 `self.s`，使用 IPv4（`AF_INET`）和 TCP（`SOCK_STREAM`）协议。
使用套接字对象 `self.s` 连接到服务器，服务器地址为 `address_server`。
最重要的方法是`robot_high_control(self, mode=2, gaitType=2, speedLevel=0, footRaiseHeight=0, bodyHeight=0, euler=[0,0,0], velocity=[0,0], yawSpeed=0.0, reverve=0)`：定义一个名为 `robot_high_control` 的方法，用于向机器人发送高级控制指令。该方法接收多个参数，如 `mode`、`gaitType` 等，用于指定机器人的运动模式、步态类型等。
最后，将传入的参数组成一个列表 `data`，使用 `json.dumps()` 方法将列表 `data` 转换为 JSON 格式的字符串。再将 JSON 格式的字符串编码为 UTF-8，转换为字节串并发送到服务器。

### (4). 赛项业务实现

在最终的业务实现中，我们首先导入`asyncio`, `time`, `numpy`, `cv2`, `requests`, `threading` 等库用于异步操作、时间处理、数组操作、图像处理、网络请求和多线程处理。

导入`Camera` 和 `RobotConnector` 类来自自定义模块 `core.Camera` 和 `core.robot_connector`，分别用于处理摄像头图像和机器人连接。

然后在main.py控制程序中定义了各个颜色的范围区间，然后实例化视频流对象用于读取视频流，定义倾倒区列表和运行停止标志用于控制线程的执行。

在程序启动时，首先通过发送ws消息控制机器人移动到赛道上，然后创建图像读取线程和运动控制线程。

在图像读取线程中，循环获取流并截图，将图像储存到队列中。

在业务主线程中，首先开启一个死循环，在循环中第一步从队列读取图像，获取图像的高度和宽度，再执行颜色判断的部分，当有对应的颜色时，判断颜色的区间以及是否为读取，如果没有被读取，则进行环岛业务操作，否则接着执行下面的代码。

在主要的运动部分，通过图像区域分割法来计算角度，同时限制当角度在15和45之间时调整方向，调整的数值是角度/10即舵机线速度，如果需要调整角度，则指定yawspeed 为 angle/10，否则就只执行直行消息，并且在这两个消息发送间隔0.02秒以使机器人的响应更加平滑。

### (5).颜色提取

我们定义一个函数名为`get_color_block`寻找图像中指定颜色范围的区域：使用HSV颜色空间定义颜色范围，通过形态学操作精炼掩膜，然后找到最大的颜色区域。
函数接受的参数：
img: 输入的BGR图像。  
color_lower: 颜色范围的下限，以HSV格式表示。  
color_upper: 颜色范围的上限，以HSV格式表示。  
square: 最小区域面积，用于过滤较小的色块，默认为None（不进行过滤）

首先，将BGR颜色空间转为HSV颜色空间，使用`cv2.cvtColor()`方法，然后创建颜色掩膜，通过`cv2.inRange()`，再创建一个5x5的核，用于进行形态学操作，通过opencv找到颜色掩膜的轮廓，找到面积最大的轮廓来获取最大的轮廓的边界框 (x, y, w, h)，其中，x:颜色区域起始的x坐标，Y为y坐标，w为区域宽度，y为区域高度。

然后检查是否满足最小面积要求，如果满足则返回颜色区域信息，否则，返回None。

### (6).计算运动参数

运动控制参数的计算技术主要体现在根据摄像头捕捉到的图像中的黄色路径位置和形状来决定机器人的运动方向。这些参数的计算技术包括路径的中线检测、曲率计算和基于这些信息的运动决策。

首先，程序通过摄像头实时获取图像并将其转换为 HSV 色彩空间。在 HSV 空间中，黄色路径被提取出来，生成了一个二值化掩码。这个掩码用于检测路径的中线和计算曲率，从而决定机器人的运动控制参数。

在 `calculate_center_line_and_curvature` 函数中，程序沿着图像的每一行扫描黄色区域的位置，并计算每一行黄色像素的中心点。所有中心点构成了路径的中线。这条中线描述了当前路径的走向，同时反映了机器人与路径中心的相对位置。

通过将中线拟合为一条二次多项式曲线，程序得到了路径的曲率。曲率的大小和符号可以用来判断路径是否出现转弯以及转弯的方向。具体地，二次项系数（`fit[0]`）直接决定了曲率的大小。曲率越大，说明路径弯曲得越明显，曲率的符号则决定了转弯方向。

在 `detect_turn_with_center_line` 函数中，程序根据中线的位置偏移和曲率值来决定机器人的运动控制指令。具体决策如下：

1. **横向移动**：如果中线的平均位置偏离图像中心超过一定阈值（如 90 像素），程序判断机器人偏离了赛道中心，需要进行横向移动以回到路径中心。此时，通过判断偏移的方向，选择左移（`Move Left`）或右移（`Move Right`）。
2. **转弯**：如果路径的曲率大于设定的阈值（如 0.01），程序判断路径出现了显著的弯曲，需要进行转弯操作。此时，曲率的符号决定了转弯的方向。
3. **直行**：当中线偏移和路径曲率都在设定的阈值范围内时，程序认为机器人可以直行，无需额外调整。

根据决策的运动方向，程序生成对应的控制指令。这些指令包括：

- 横向移动（设置 `velocity` 参数来控制左右移动的速度）。
- 转弯（设置 `yawSpeed` 参数来控制转弯速度）。
- 直行（设置前进速度）。

这些控制指令是通过字典形式存储的，例如 `cmd = dict(mode=2, gaitType=1, velocity=[0, 0.1])`。程序可以进一步调用 `robot.robot_high_control(**cmd)` 将这些指令传递给机器人执行。

综上，整个运动控制参数的计算技术围绕路径中线和曲率展开，结合图像分析结果，决定机器人在赛道中的运动策略，从而实现自动循迹的效果。

运行表现如下图所示：
![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/8363e9c18cab5ea75bee656aaaf472c7.png)


![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/ca9c5172d5e03874db9b4ffd53701004.png)


### (7).物料识别

这个程序的核心目标是通过摄像头实时捕获图像，然后通过颜色过滤和形状检测来识别特定的物体。在识别过程中，程序会拉近图像、裁剪掉无关区域，并根据物体的外接圆半径来避免在同一物体上重复识别多个形状。

首先，程序通过 `cv2.VideoCapture(0)` 打开摄像头，获取实时的图像数据。在每一帧图像捕获后，程序首先进行缩放操作，通过调整图像的比例来拉近场景，使得物体在图像中显得更大、更易于检测。随后进行裁剪，主要保留图像中央区域，去除可能干扰识别的边缘部分。这个步骤确保图像的处理更加集中在关键信息上，同时减少无关背景对识别的干扰。

接下来，程序将裁剪后的图像转换为 HSV 颜色空间。HSV 是一种更适合颜色过滤的颜色模型。为了准确识别红色物体，程序设置了两个不同的红色阈值区间（低端和高端），并使用这两个阈值创建二值化掩码，最终将两个掩码进行合并，得到整个红色区域的掩码。这一步确保了在不同光照条件下，红色物体能够被稳定地检测出来。

在得到红色区域的掩码后，程序通过形态学操作（如闭运算）去除图像中的噪声，以获得更干净的轮廓。然后，程序使用 `cv2.findContours` 寻找掩码中的轮廓。对于每个轮廓，程序计算它的近似多边形，提取出关键顶点，并通过顶点数量和形状特征（如长宽比）来判断物体的类型。具体来说，如果检测到三个顶点，程序认为这是一个三棱锥；如果检测到四个顶点且长宽比接近 1，则认为是正方体；如果长宽比不接近 1，则判断为圆柱体；而检测到超过 8 个顶点的圆形轮廓则被识别为半球。

为避免在同一物体上重复识别多个形状，程序引入了外接圆的计算。对于每个轮廓，程序使用 `cv2.minEnclosingCircle` 获取轮廓的最小外接圆，并基于其半径进行筛选。程序设置了一个最小半径阈值，确保只处理较大的、真实的物体轮廓，同时通过比较已经识别出的物体的半径，避免在相似半径的区域重复识别不同的形状。这种方法有效防止了一个物体被多个形状同时识别的情况，提高了识别的准确性和唯一性。

最终，程序将识别到的物体在图像中进行标注，显示其形状和对应的编号，同时在控制台输出识别结果。整个流程在一个循环中实时进行，允许用户在摄像头窗口中观察到识别过程，并通过按下 `q` 键随时退出程序。通过这种实时处理，程序能够稳定地识别和标注物体，适用于在固定场景下的物体检测和分类任务。


在运行时的表现如下图所示：

![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/7a3b2805193f42fe61ffa31eae32ceef.png)


### (8). Aruco 识别

在比赛任务中，机器人需要实现对障碍物的避让和物资倾倒区的识别，这对整体路径规划和任务执行的成功至关重要。使用 ArUco 标签来进行这些功能的实现具有高度的可行性。通过在特定位置放置不同 ID 的 ArUco 标签，机器人可以精确识别出前方是障碍物、倾倒区还是其他关键区域，并基于识别结果进行相应的动作。这一技术方案的目标是利用 ArUco 标签提供环境中的信息提示，从而帮助机器人在复杂场景中做出正确的决策。

本方案的实现依赖于以下技术：

- **计算机视觉库**：使用 OpenCV 中的 ArUco 模块进行标签检测、解码和位置判断。
- **机器人运动控制模块**：通过识别特定标签，触发机器人的避障、路径调整或物资倾倒动作。
- **多线程与队列管理**：在实时场景下，采用多线程来并行处理图像采集、标签识别与运动控制决策，确保系统响应的实时性和稳定性。

在机器人运动过程中，摄像头持续采集视频流，图像传递至图像处理模块进行实时分析。图像处理的步骤包括：

1. 将采集到的图像转换为灰度图，减少颜色干扰。
2. 使用 OpenCV 的 ArUco 检测函数识别标签，提取标签的角点坐标和 ID 信息。
3. 根据检测到的标签 ID 判断其类型，并触发对应的功能。

技术方案实现的表现如下图所示：

![小杜的个人图床](http://src.xiaodu0.com/2024/08/16/35081ffb5aaa36d199e7bd00a13c2ef7.png)


### (9) .避障设计

避障程序需要使用头部摄像头，因此传输中我们开启两个头部板卡的图像发送的线程，并且从不同的端口发送UDP数据，在接收端，对于脸部摄像头的数据只需要识别aruco tag即可，不需要进行其他的业务，当识别到aruco tag的ID为5的aruco Tag时，协调运动主程序执行避障逻辑。

为了避障设计更加严谨，我们使用的技术方案是结合颜色识别与aruco识别进行检验，当识别到绿色的区域时，也就是障碍物的颜色，进一步识别绿色区域的内容，如果其中含有ID为5的aruco TAG时，进行避障操作。


## 3. 比赛程序

### (1).头部板卡

头部板卡我们使用SDK发送图像，由于需要发送两个摄像头的数据，因此我们对其进行的简单的二次开发来使用两个ymal配置文件发送不同摄像头的数据：

#### a. C++程序
example_putImagetrans.cc：
```C++
#include <UnitreeCameraSDK.hpp>  
#include <unistd.h>  
  
int main(int argc, char *argv[])  
{  
    int cam_num = 1;  
    if (argc>=2)  
        cam_num = std::atoi(argv[1]);  
  
    // int cam_num = 1; // 1,2 the number of cameras used  
    // nano_id dev_id   port_id   位置  
    //   13       0      9202     下巴  
    //   13       1      9201     前方  
    //   14       0      9203     左方  
    //   14       1      9204     右方  
    //   15       0      9205     腹部（默认）  
    int cam_id = 0; // the id of the camera used if cam_num is 1  
    if (cam_num == 1){  
        UnitreeCamera cam("trans_rect_config_"+ std::to_string(cam_id) +".yaml"); ///< init camera by device node number  
        if(!cam.isOpened())   ///< get camera open state  
            exit(EXIT_FAILURE);     
        cam.startCapture(true,false); ///< disable share memory sharing and able image h264 encoding  
  
        usleep(500000);  
        while(cam.isOpened())  
        {  
            cv::Mat left,right,feim;  
            if(!cam.getRectStereoFrame(left,right))  
            {  
                  
                usleep(1000);  
                continue;  
            }  
            char key = cv::waitKey(1);  
            if(key == 27) // press ESC key  
            break;  
        }  
          
        cam.stopCapture(); ///< stop camera capturing  
    }  
    else {  
        UnitreeCamera cam1("trans_rect_config_0.yaml");   
        UnitreeCamera cam2("trans_rect_config_1.yaml");  
        if(!cam1.isOpened())   
            exit(EXIT_FAILURE);     
        if(!cam2.isOpened())  
            exit(EXIT_FAILURE);     
        cam1.startCapture(true,false);   
        cam2.startCapture(true,false);   
          
        usleep(500000);  
        while(cam1.isOpened())  
        {  
            cv::Mat left1,right1,feim1,left2,right2,feim2;  
            if(!cam1.getRectStereoFrame(left1,right1))  
            {  
                usleep(500);  
                continue;  
            }  
            if(!cam2.getRectStereoFrame(left2,right2))  
            {  
                usleep(500);  
                continue;  
            }  
            char key = cv::waitKey(1);  
            if(key == 27) // press ESC key  
            break;  
        }  
      
      
    }  
      
    return 0;  
}
```


#### (2). yaml配置文件

trans_rect_config_0.yaml：
```xml
%YAML:1.0  
---  
# unimportant  
LogLevel: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 1. ]  
# unimportant  
Threshold: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 190. ]  
# unimportant. It is recommended not to change  
Algorithm: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [1. ]  
#UDP address for image transfer   192.168.123.IpLastSegment  
IpLastSegment: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 14. ]  
#DeviceNode  
DeviceNode: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 0. ]  
#fov (perspective 60~140) hFov: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 90. ]  
#image size ([1856,800] or [928,400])  
FrameSize: !!opencv-matrix  
   rows: 1  
   cols: 2  
   dt: d  
   data: [ 928., 400. ]  
#  
RectifyFrameSize: !!opencv-matrix  
   rows: 1  
   cols: 2  
   dt: d  
   data: [ 928., 800. ]  
#FrameRate  
FrameRate: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 3e+01 ]  
#0 ori img - right  1 ori img - stereo  2 rect img - right  3 rect img - stereo   -1 不传图  
Transmode: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 2. ]   
#Transmission rate  
Transrate: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 3e+01 ]   
# unimportant  
Depthmode: !!opencv-matrix  
   rows: 1  
   cols: 1  
   dt: d  
   data: [ 1. ]   
Reserved: !!opencv-matrix  
   rows: 3  
   cols: 3  
   dt: d
```


### (2).运动控制板卡

#### a. websocket服务端

server_robotcontrol.py:

```python
import socket  
import threading  
import json  
  
from unitree_python_sdk import Unitree_Robot_High  
unitree_robot = Unitree_Robot_High()  
  
clients = {}  
  
class client(object):  
    def __init__(self, socket, addr, username):  
        self.addr = addr[0]  
        self.port = addr[1]  
        self.username = username  
        self.socket = socket  
      
    def send(self, msg):  
        self.socket.send(msg)  
      
    def recv(self, mtu=1024):  
        try:  
            data = self.socket.recv(mtu)  
            if not data:  
                return False  
            return data  
        except:  
            return False  
    def close(self):  
        try:  
            self.socket.close()  
            return True  
        except:  
            return False  
  
    def id(self):  
        return '{0}:{1}'.format(self.addr, self.port)  
  
  
def new_client(c):  
    try:  
        while True:  
            data = c.recv()  
            if not data:  
                break  
            else:  
                data = json.loads(data)  
                # print(data)  
                unitree_robot.execute(data[0],   # mode  
                                      data[1],   # gaitType  
                                      data[2],   # speedLevel  
                                      data[3],   # footRaiseHeight  
                                      data[4],   # bodyHeight  
                                      data[5],   # euler  
                                      data[6],   # velocity  
                                      data[7],   # yawSpeed  
                                      data[8])   # reserve  
  
    except socket.error as e:  
        print('({0})Socket error: {1}'.format(c.id(), e))  
    except Exception as e:  
        print('({0})Other exception: {1}'.format(c.id(), e))  
    finally:  
        print('({0})Client leave.'.format(c.id()))  
        c.close()  
        clients.pop(c.id())  
  
  
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  
address = ('192.168.123.161', 8000)  
s.bind(address)  
s.listen(16)  
print('Listening...')  
  
while True:  
    conn, addr = s.accept()  
    c = client(conn, addr, '')  
    clients[c.id()] = c  
    t = threading.Thread(target=new_client, args=(c,))  
    t.start()  
    print('({0})Client entry.'.format(c.id()))
```

#### b.sdk文件

unitree_python_sdk.py:
```python
import sys  
# sys.path.append('/home/unitree/go1_guide/raspberrypi/unitree_legged_sdk/lib/python/arm64')  
sys.path.append(r'../core')  
import robot_interface as sdk  
  
import unitree  
  
class Unitree_Robot_High():  
    def __init__(self):  
        self.udp = sdk.UDP(unitree.HIGHLEVEL, 8080, "192.168.123.161", 8082)  
        self.cmd = sdk.HighCmd()  
        self.state = sdk.HighState()  
        self.udp.InitCmdData(self.cmd)  
  
        self.init_cmd()  
  
    def init_cmd(self):  
        self.cmd.mode = 0      # 0:idle, default stand      1:forced stand     2:walk continuously  
        self.cmd.gaitType = 0  
        self.cmd.speedLevel = 0  
        self.cmd.footRaiseHeight = 0  
        self.cmd.bodyHeight = 0  
        self.cmd.euler = [0, 0, 0]  
        self.cmd.velocity = [0, 0]  
        self.cmd.yawSpeed = 0.0  
        self.cmd.reserve = 0  
    def send_UDP(self):  
        self.udp.SetSend(self.cmd)  
        self.udp.Send()  
      
    def execute(self, mode=2, gaitType=0, speedLevel=0,   
                      footRaiseHeight=0, bodyHeight=0,   
                      euler=[0,0,0], velocity=[0,0], yawSpeed=0.0, reverve=0):  
        self.init_cmd()  
        self.cmd.mode = mode  
        self.cmd.gaitType = gaitType  
        self.cmd.speedLevel = speedLevel  
        self.cmd.footRaiseHeight = footRaiseHeight  
        self.cmd.bodyHeight = bodyHeight  
        self.cmd.euler = euler  
        self.cmd.velocity = velocity  
        self.cmd.yawSpeed = yawSpeed  
        self.cmd.reserve = reverve  
        self.send_UDP()  
  
    # def pose(self, roll, pitch, yaw, bodyHeight):  
    #     self.init_cmd()    #     self.cmd.mode = 1    #     self.cmd.bodyHeight = bodyHeight    #     self.cmd.yaw = yaw    #     self.cmd.pitch = pitch    #     self.cmd.roll = roll    #     self.send_UDP()    def getState(self):  
        self.udp.Recv()  
        self.udp.GetRecv(self.state)  
        return self.state
```

### (3).14板卡

#### a. socket连接对象
robot_connect.py:
```python
import socket  
import json  
  
  
class RobotConnector():  
    def __init__(self, ip_address='192.168.123.161', port=8000):  
        address_server = (ip_address, port)  
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  
        self.s.connect(address_server)  
  
    def robot_high_control(self, mode=2, gaitType=2, speedLevel=0,  
                      footRaiseHeight=0, bodyHeight=0,  
                      euler=[0,0,0], velocity=[0,0], yawSpeed=0.0, reverve=0):  
        data = [mode, gaitType, speedLevel, footRaiseHeight, bodyHeight, euler, velocity, yawSpeed, reverve]  
        data = json.dumps(data)  
        self.s.send(bytes(data.encode('utf-8')))  
  
    # 机械臂控制指令  
    def arms_control(self,action):  
        data = {"action":action}  
        data = json.dumps(data)  
        self.s.send(bytes(data.encode('utf-8')))
```

#### b. 相机处理模块

Camera.py:
```python
# -*- coding: utf-8 -*-  
'''copyright Copyright (c) 2020-2021, Hangzhou Yushu Technology Stock CO.LTD. All Rights Reserved  
writen by Zhentao Xie  
supporter: Zhentao Xie xiezhentao_1998@163.com  
'''  
  
import cv2  
import queue  
import threading  
  
class Camera:  
    def __init__(self, cam_id=None, width=640, height=480, frame_queue=None):  
        self.cam_id = cam_id  
        self.width = width  
        self.height = height  
        self.frame_queue = frame_queue if frame_queue else queue.Queue()  # 使用传入的队列或默认的队列  
        self.cap = None  
  
    def get_img(self):  
        IpLastSegment = "14"  
        cam = self.cam_id  
        udpstrPrevData = "udpsrc address=192.168.123." + IpLastSegment + " port="  
        udpPORT = [9201, 9202, 9203, 9204, 9205]  
        udpstrBehindData = " ! application/x-rtp,media=video,encoding-name=H264 ! rtph264depay ! h264parse ! omxh264dec ! videoconvert ! appsink"  
        udpSendIntegratedPipe_0 = udpstrPrevData + str(udpPORT[cam]) + udpstrBehindData  
        print(udpSendIntegratedPipe_0)  
        self.cap = cv2.VideoCapture(udpSendIntegratedPipe_0)  
  
    def run(self):  
        self.get_img()  
        while True:  
            ret, frame = self.cap.read()  
            if not ret:  
                print("未能接收到视频帧")  
                break  
            frame = cv2.resize(frame, (int(self.width), int(self.height)))  
            if self.cam_id == 1:  
                frame = cv2.flip(frame, -1)  
  
            if frame is not None:  
                print("收到图像")  
                self.frame_queue.put(frame)  # 将图像帧放入队列中  
  
            if cv2.waitKey(1) & 0xFF == ord('q'):  
                break  
  
        self.cap.release()  
        cv2.destroyAllWindows()
```

#### c.PID控制程序

PID.py:
```python
   
class PID():  
    def __init__(self, dt, max, min, Kp, Kd, Ki):  
       self.dt = dt    # 循环时长  
       self.max = max  # 操作变量最大值  
       self.min = min  # 操作变量最小值  
       self.Kp = Kp         # 比例增益  
       self.Kd = Kd         # 微分增益  
       self.Ki = Ki         # 积分增益  
       self.integral = 0    # 直到上一次的误差值  
       self.pre_error = 0   # 上一次的误差值  
 def calculate(self, setPoint, pv):  
       # 其中 pv:process value 即过程值，  
       error = setPoint - pv           # 误差  
       Pout = self.Kp * error          # 比例项  
       self.integral += error * self.dt  
       Iout = self.Ki * self.integral  # 积分项  
       derivative = (error - self.pre_error)/self.dt  
       Dout = self.Kd * derivative     # 微分项  
 output = Pout + Iout + Dout     # 新的目标值  
 if(output > self.max):  
          output = self.max  
       elif(output < self.min):  
          output = self.min  
   
       self.pre_error = error         # 保存本次误差，以供下次计算  
       return output  
  
  
  
if __name__ == '__main__':  
    import matplotlib.pyplot as plt  
    t = range(150)  
    pid = PID(0.1, 100, -100, 0.1, 0.01, 0.5)  
    val = 20  
    z = []  
    for i in t:  
        inc = pid.calculate(0, val)  
        print("val:{} inc:{}".format(val,inc))  
        z.append(20-val)  
        val += inc  
    plt.figure(figsize=(8,6), dpi = 80)  
    plt.plot(t,z,color="blue",linewidth=1.0,linestyle="-")  
    plt.show()
```

#### d. 入口程序

run.py:
```python
import cv2  
import cv2.aruco as aruco  
import queue  
import threading  
from function import *  
from Camera import Camera  
from config import *  
  
if __name__ == "__main__":  
    # 图像队列  
    frame_queue = queue.Queue()  
  
    cam = Camera(cam_id=1, frame_queue=frame_queue)  
    # 摄像头采集线程  
    cam_thread = threading.Thread(target=cam.run)  
    # 运动主线程  
    sport_thread = threading.Thread(target=running,args=(frame_queue,))  
  
  
    # 启动线程  
    cam_thread.start()  
    sport_thread.start()  
  
  
    cam_thread.join()
```
#### e. 主运行程序

main.py:
```python
import asyncio  
import time  
import numpy as np  
import cv2  
import requests  
import threading  
from core.Camera import Camera  # 请确保 Camera 类支持异步 getframe 方法  
from core.robot_connector import RobotConnector  
  
# 定义最小速度和最大速度  
min_speed, max_speed = 0.05, 0.2  # 0.31  #0.345  0.333  #0.42  
# 实例化机器人连接对象  
robot = RobotConnector(ip_address='192.168.123.161', port=8000)  
  
# 定义黄色部分的范围，黄色部分是道路颜色识别  
road_yellow_min = np.array([25, 34, 105], np.uint8)  # 25 ,34, 105  
road_yellow_max = np.array([65, 225, 220], np.uint8)  # 45,225,220  
  
# road_yellow_min = np.array([20, 0, 99])  # 调整后的最小值  
# road_yellow_max = np.array([95, 255, 255])  # 调整后的最大值  
  
# 定义蓝色蓝色范围  
blue_color_min = np.array([117, 100, 100], np.uint8)  
blue_color_max = np.array([130, 250, 250], np.uint8)  
  
# 定义红色范围  
red_color_min = np.array([0, 100, 100], np.uint8)  
red_color_max = np.array([10, 255, 255], np.uint8)  
  
# 定义绿色范围  
green_color_min = np.array([30, 70, 50], np.uint8)  
green_color_max = np.array([90, 255, 120], np.uint8)  
  
# 定义白色范围  
white_color_min = np.array([0, 0, 221], np.uint8)  
white_color_max = np.array([180, 30, 255], np.uint8)  
  
# 定义黑色范围  
black_color_min = np.array([0, 0, 0], np.uint8)  
black_color_max = np.array([180, 255, 56], np.uint8)  
  
# 定义紫色范围  
purple_color_min = np.array([125, 20, 0], np.uint8)  
purple_color_max = np.array([255, 255, 100], np.uint8)  
  
# 这两个video指头部的Nano摄像头的Camera对象实例  
# vedio1 = Camera("http://192.168.123.13:5000/video1")  
vedio2 = Camera("http://192.168.123.13:5000/video2")  
  
# 获取视频流  
stream1 = requests.get('http://192.168.123.13:5000/video2', stream=True)  # 下巴相机  
stream0 = requests.get('http://192.168.123.13:5000/video1', stream=True)  # 头部相机  
  
# 定義傾倒區  
area = [0, 0, 0, 0]  
  
# 定义图像队列  
queue = []  
  
running = True  
stop = False  
euler_stop = False  
  
"""  
写入图像队列  
"""  
  
  
def writeQueue(img):  
    if len(queue) == 10:  
        queue.pop(0)  
    queue.append(img)  
  
  
def readQueue():  
    if len(queue) > 0:  
        if queue[len(queue) - 1] is not None:  
            return queue[len(queue) - 1]  
  
  
"""  
获取相机 n=0 头部 n=1 下巴  
"""  
  
  
def getFrame(n):  
    # 根据 n 获取不同的流对象  
    if n == 1:  
        stream = stream1  
    else:  
        stream = stream0  
  
    bytes_data = b''  # 初始化一个字节串用于保存数据块  
  
    # 读取视频流数据  
    for chunk in stream.iter_content(chunk_size=1024):  
        bytes_data += chunk  
        a = bytes_data.find(b'\xff\xd8')  # 找到JPEG图像的起始标志  
        b = bytes_data.find(b'\xff\xd9')  # 找到JPEG图像的结束标志  
  
        # 如果找到一帧完整的JPEG图像  
        if a != -1 and b != -1:  
            jpg = bytes_data[a:b + 2]  # 提取完整的JPEG图像  
            bytes_data = bytes_data[b + 2:]  # 截断已经处理过的数据  
            img = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)  # 解码图像  
            writeQueue(img)  
  
  
def save(img, result, name):  
    """  
    保存图像并标注检测结果。  
    如果检测结果存在，则在图像上画出检测到的物体的边界框，并保存图像。    参数:  
    img: 输入的图像。  
    result: 检测结果，包含物体的左上角坐标(x, y)、宽度(w)和高度(h)。  
    name: 保存的图像文件名。  
    """    # 检查检测结果是否存在  
    if result:  
        # 解析检测结果，并为物体画出红色边界框  
        x, y, w, h = result  
        color_image = cv2.rectangle(img,  
                                    (x, y),  
                                    (x + w, y + h),  
                                    (0, 0, 255), 2)  
    # 保存处理后的图像  
    cv2.imwrite(name + '.jpg', img)  
    # 输出保存成功的提示信息  
    print('saved')  
  
  
def detect_turn_with_angle(frame):  
    frame = cv2.resize(frame, (640, 480))  
    height, width, _ = frame.shape  
  
    # 转换为HSV颜色空间  
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)  
  
    # 应用颜色阈值以检测黄色  
    mask = cv2.inRange(hsv, road_yellow_min, road_yellow_max)  
    #    mask = cv2.inRange(hsv, (20, 0, 99), (95, 255, 255))  
    # 初始化方向和角度信息  
    directions = []  
    angles = []  
  
    # 定义三个感兴趣的区域（ROI）  
    rois = [  
        (height * 2 // 3, height),  # 下部区域  
        (height // 3, height * 2 // 3),  # 中部区域  
        (0, height // 3)  # 上部区域  
    ]  
  
    output_frame = frame.copy()  
  
    for idx, (startY, endY) in enumerate(rois):  
        roi = mask[startY:endY, :]  
  
        # 查找黄色区域的轮廓3656+  
        contours, _ = cv2.findContours(roi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  
        # cv2.imshow("a",contours)  
        if contours:  
            # 计算所有黄色区域的中心  
            mask_moments = cv2.moments(roi)  
            if mask_moments["m00"] != 0:  
                cX = int(mask_moments["m10"] / mask_moments["m00"])  
            else:  
                cX = width // 2  
  
            # 可视化每个ROI的中心点  
            cv2.circle(output_frame[startY:endY, :], (cX, (endY - startY) // 2), 5, (0, 255, 0), -1)  
            cv2.putText(output_frame, f'ROI-{idx + 1} Center: ({cX},{(endY - startY) // 2})',  
                        (cX - 50, (endY - startY) // 2 - 10 + startY), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)  
  
            # 计算转弯角度  
            angle = -(np.arctan2(cX - (width // 2), height * 0.5) * 180 / np.pi)  
            angles.append(angle)  
  
            # 判断方向  
            if angle < -15:  
                directions.append("Left")  
            elif angle > 15:  
                directions.append("Right")  
            else:  
                directions.append("Straight")  
  
        else:  
            directions.append("No yellow")  
            angles.append(0)  
  
    # 决定最终方向和角度  
    final_direction = "Straight"  
    final_angle = 0.0  
  
    if "Left" in directions:  
        final_direction = "Left"  
        final_angle = min(angles)  # 取最左侧角度  
    elif "Right" in directions:  
        final_direction = "Right"  
        final_angle = max(angles)  # 取最右侧角度  
  
    return True, final_direction, final_angle, output_frame  
  
  
def get_color_block(img, color_lower, color_upper, square=None):  
    """  
    寻找图像中指定颜色范围的区域。  
    使用HSV颜色空间定义颜色范围，通过形态学操作精炼掩膜，然后找到最大的颜色区域。  
    参数:  
    img: 输入的BGR图像。  
    color_lower: 颜色范围的下限，以HSV格式表示。  
    color_upper: 颜色范围的上限，以HSV格式表示。  
    square: 最小区域面积，用于过滤较小的色块，默认为None（不进行过滤）。  
    返回:  
    如果找到符合条件的色块，则返回该色块的左上角坐标、宽度和高度；  
    如果没有找到色块或找到的色块面积小于指定的最小面积，则返回None。  
    """    # 将BGR颜色空间转为HSV颜色空间  
    hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  
    # 创建颜色掩膜  
    color_mask = cv2.inRange(hsvFrame, color_lower, color_upper)  
    # 创建一个5x5的核，用于进行形态学操作  
    kernal = np.ones((5, 5), "uint8")  
  
    # 使用5x5的核进行膨胀操作  
    color_mask = cv2.dilate(color_mask, kernal)  
    # 找到颜色掩膜的轮廓  
    contours, _ = cv2.findContours(color_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  
  
    if len(contours) == 0:  
        return None  
    else:  
        # 找到面积最大的轮廓  
        area = max(contours, key=cv2.contourArea)  
        # 获取最大的轮廓的边界框 (x, y, w, h)        x, y, w, h = cv2.boundingRect(area)  
        # x:颜色区域起始的x坐标，Y为y坐标，w为区域宽度，y为区域高度  
        # 检查是否满足最小面积要求  
        if square and w * h < square:  
            return None  
        else:  
            # # 在原图上绘制边界框  
            # cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  
            # # 显示原图  
            # cv2.imshow('Detected Color Block', img)  
            # cv2.waitKey(1)  # 1 ms delay to allow for display update            return [x, y, w, h]  
  
  
def detect_balck(img):  
    res = get_color_block(img, black_color_min, black_color_max)  
    return res  
  
  
def detect_white(img):  
    res = get_color_block(img, white_color_min, white_color_max)  
    return res  
  
  
def detect_purple(img):  
    res = get_color_block(img, purple_color_min, purple_color_max)  
    return res  
  
  
def detect_green(img):  
    res = get_color_block(img, green_color_min, green_color_max)  
    return res  
  
  
def pour(n):  
    print("倾倒")  
    for i in range(30):  
        robot.robot_high_control(mode=1, gaitType=0, euler=[-0.2, 0, 0])  
        time.sleep(0.1)  
    area[n] = 1  
    time.sleep(1)  
  
def euler_thread():  
    """子线程发送欧拉角信号"""  
    global euler_stop  
    print("倾倒")  
    while not euler_stop:  
        robot.robot_high_control(mode=2, gaitType=1, yawSpeed=1)  
        time.sleep(0.2)  
        for i in range(50):  
            for j in range(5):  
                robot.robot_high_control(mode=2,gaitType=1,velocity=[0.1, 0])  
                time.sleep(0.05)  
            robot.robot_high_control(mode=2, gaitType=1, yawSpeed=1.5)  
            time.sleep(0.05)  
        time.sleep(1)  
        robot.robot_high_control(mode=1, gaitType=1, bodyHeight=-0.1,euler=[-1, 0, 0])  
        time.sleep(1)  
        euler_stop=True  
    # 左转  
    # while euler_stop == True:  
    #     robot.robot_high_control(mode=2, gaitType=1, yawSpeed=2, velocity=[0, 0])    #     for i in range(30):    #         robot.robot_high_control(velocity=[0.1, 0])    #         time.sleep(0.02)    #         robot.robot_high_control(mode=2, gaitType=1, yawSpeed=1, velocity=[0, 0])    #         time.sleep(0.02)    #     time.sleep(1)    #     robot.robot_high_control(mode=1,euler=[-1, 0, 0])    #     time.sleep(1)    #     euler_stop=True  
  
def through(n):  
    global running,stop,euler_stop  
    key = 0  
    max_speed2 = max_speed  
    velocity = [0, 0]  # 方向  
    while True:  
        while 1:  
            frame = readQueue()  
            if frame is not None:  
                # cv2.imshow("Frame", frame)  
                # cv2.waitKey(1)                break  
        h_frame, w_frame = frame.shape[0:2]  
        x_center = w_frame / 2  
  
        # 绿色判断  
        if 1 in n and area[0] == 0:  
            res = detect_green(frame)  
            if res is not None and res[2] > 80 and res[3] > 80:  
                running = False  
                stop = True  
                area[0] = 1  
                # 进入倾倒区  
                robot.robot_high_control(velocity=[0, 0.6])  
                # 启动子线程发送欧拉角信号  
                t_euler = threading.Thread(target=euler_thread, name="欧拉角发送线程")  
                t_euler.start()  
                # 等待子线程完成  
                t_euler.join()  
                time.sleep(3)  
                running = True  
                stop = False  
                # time.sleep(0.1)  
                # task = threading.Timer(3,pour,args={0})  
                # robot.robot_high_control(velocity=[0.2,0])                # for i in range(30):                #     robot.robot_high_control(velocity=[0.2,0])                #     time.sleep(0.1)                #     robot.robot_high_control(velocity=[0.2,0])                #     time.sleep(0.1)                # time.sleep(2)                # robot.robot_high_control(mode=1,euler=[-1,0,0])                # # 倾倒  
                # # robot.robot_high_control(mode=1,gaitType=2,euler=[-1,0,0])  
                # # # time.sleep(0.1)                # robot.robot_high_control(mode=2,gaitType=2,velocity=[0.1,0])                # 记录  
                # time.sleep(2)  
                continue  
    # 二号红色判断  
        # if 2 in area and n[0] == 0:  
        #     res = detect_green(frame)        #     if res is not None and res[2] > 100 and res[3]>100:        #         # 进入倾倒区  
        #         robot.robot_high_control(yawSpeed=2.5)  
        #         time.sleep(1)        #         # 倾倒  
        #         robot.robot_high_control(mode=1,gaitType=2,euler=[-1,0,0])  
        #         # 记录  
        #         n[0]=1  
        #         continue    # 计算转弯角度  
        if running == True and stop == False:  
            detected, direction, angle, result_frame = detect_turn_with_angle(frame)  
            # if abs(angle) > 10 and abs(angle) < 50:  
            if abs(angle) > 15:  
                # print("angle:",angle)  
                robot.robot_high_control(mode=2, gaitType=1, yawSpeed=angle / 10, velocity=[0, 0])  
                print("angle:", angle)  
                time.sleep(0.02)  
                # continue  
            robot.robot_high_control(mode=2, gaitType=1, velocity=[0.1, 0])  
            time.sleep(0.05)  
    # cv2.imshow("Original Frame", frame)  
    # cv2.imshow("Result Frame", result_frame)    # cv2.waitKey(1)  
  
if __name__ == '__main__':  
    for i in range(20):  
        #         robot.robot_high_control(velocity=[0.6, 0.00], yawSpeed=0)/  
        robot.robot_high_control(mode=2, gaitType=2, velocity=[0, 0.2])  
        time.sleep(0.1)  
    print("开始循迹")  
    # 创建读取线程  
    t1 = threading.Thread(target=getFrame, name="读取视频流", args={1})  
    t2 = threading.Thread(target=through, name="运动", args={(1, 2)})  
    # 倾倒区：1号为绿色，转角环岛、2号为红色，转角环岛，3号为黑色，十字环岛，4号为紫色，十字环岛。  
    t1.start()  
    t2.start()  
    # asyncio.run(through())  
    # through()
```


#### f. 功能函数程序
function.py:
```python
import cv2  
import cv2.aruco as aruco  
import time  
from config import *  
  
  
def detect_aruco_tag(frame):  
    # 定义字典和检测器参数  
    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)  # 使用6x6, 250种类的标签  
    parameters = aruco.DetectorParameters_create()  
  
    # 将图像转换为灰度图  
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  
  
    # 检测ArUco标记  
    corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)  
  
    # 如果检测到了ID标签  
    if ids is not None:  
        for i in range(len(ids)):  
            tag_id = ids[i][0]  
            print(f"识别到ArUco标签ID: {tag_id}")  
            # 绘制检测到的标记边框  
            aruco.drawDetectedMarkers(frame, corners, ids)  
            return True,tag_id,frame  
    else:  
        return False,None,None  
  
# 运动主线程  
def running(queue):  
    # go_track()  
    while True:  
        if not queue.empty():  
            frame = queue.get()  
            cv2.imshow("raw",frame)  
            res,cmd = detect_sport_cmd(frame)  
            aruco_res,tag_id,aruco_frame = detect_aruco_tag(frame)  
            if aruco_res:  
                # cv2.imshow("aruco_tag", aruco_frame)  
                process_aruco_tag(tag_id)  
            if res == True:  
                pass  
                # print(cmd)  
                # robot.robot_high_control(**cmd)                # time.sleep(0.1)        else:  
            print("图像队列为空，等待图像......")  
  
  
# 进入赛道  
def go_track():  
    for i in range(20):  
        robot.robot_high_control(mode=2, gaitType=2, velocity=[0, 0.2])  
        time.sleep(0.1)  
    print("开始循迹")  
  
  
# 计算转弯方向  
def detect_turn_with_angle(frame):  
    frame = cv2.resize(frame, (640, 480))  
    height, width, _ = frame.shape  
  
    # 转换为HSV颜色空间  
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)  
  
    # 应用颜色阈值以检测黄色  
    mask = cv2.inRange(hsv, road_yellow_min, road_yellow_max)  
    # 初始化方向和角度信息  
    directions = []  
    angles = []  
  
    # 定义三个感兴趣的区域（ROI）  
    rois = [  
        (height * 2 // 3, height),  # 下部区域  
        (height // 3, height * 2 // 3),  # 中部区域  
        (0, height // 3)  # 上部区域  
    ]  
  
    output_frame = frame.copy()  
  
    for idx, (startY, endY) in enumerate(rois):  
        roi = mask[startY:endY, :]  
  
        # 查找黄色区域的轮廓3656+  
        contours, _ = cv2.findContours(roi, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  
        # cv2.imshow("a",contours)  
        if contours:  
            # 计算所有黄色区域的中心  
            mask_moments = cv2.moments(roi)  
            if mask_moments["m00"] != 0:  
                cX = int(mask_moments["m10"] / mask_moments["m00"])  
            else:  
                cX = width // 2  
  
            # 可视化每个ROI的中心点  
            cv2.circle(output_frame[startY:endY, :], (cX, (endY - startY) // 2), 5, (0, 255, 0), -1)  
            cv2.putText(output_frame, f'ROI-{idx + 1} Center: ({cX},{(endY - startY) // 2})',  
                        (cX - 50, (endY - startY) // 2 - 10 + startY), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)  
  
            # 计算转弯角度  
            angle = -(np.arctan2(cX - (width // 2), height * 0.5) * 180 / np.pi)  
            angles.append(angle)  
  
            # 判断方向  
            if angle < -15:  
                directions.append("Left")  
            elif angle > 15:  
                directions.append("Right")  
            else:  
                directions.append("Straight")  
  
        else:  
            directions.append("No yellow")  
            angles.append(0)  
  
    # 决定最终方向和角度  
    final_direction = "Straight"  
    final_angle = 0.0  
  
    if "Left" in directions:  
        final_direction = "Left"  
        final_angle = min(angles)  # 取最左侧角度  
    elif "Right" in directions:  
        final_direction = "Right"  
        final_angle = max(angles)  # 取最右侧角度  
  
    return True, final_direction, final_angle, output_frame  
  
  
# 计算运动参数,当角度大于规定的角度时才进行转向。  
def detect_sport_cmd(frame):  
    detected, direction, angle, result_frame = detect_turn_with_angle(frame)  
    if min_angle < abs(angle) <= max_angle:  
        cv2.imshow("res",result_frame)  
        print("angle:",angle)  
        cmd = dict(mode=2, gaitType=1, yawSpeed=angle / 10, velocity=[0, 0])  
        return True, cmd  
    else:  
        return False
```


#### g. 全局参数文件：

params.py:
```python
"""  
运动参数文件  
"""  
  
import numpy as np  
from RobotConnector import RobotConnector  
  
  
  
# 机器人控制对象  
# robot = RobotConnector()  
  
# 定义最大速度和最小速度  
min_speed, max_speed = 0.05, 0.2  # 0.31  #0.345  0.333  #0.42  
  
#定义最大转角和最小转角  
min_angle = 15  
max_angle = 55  
  
# 定义绿色范围  
green_color_min = np.array([30, 70, 50], np.uint8)  
green_color_max = np.array([90, 255, 120], np.uint8)  
  
# 定义黄色部分的范围，黄色部分是道路颜色识别  
road_yellow_min = np.array([25, 34, 105], np.uint8)  # 25 ,34, 105  
road_yellow_max = np.array([65, 225, 220], np.uint8)  # 45,225,220
```

#### h. 物料识别
```python
import cv2  
import numpy as np  
  
  
def identify_shape(approx):  
    """  
    通过轮廓的近似多边形顶点数和形状比例判断物体类型。  
    """    if len(approx) == 3:  
        return "Triangle", 1  # 三棱锥  
    elif len(approx) == 4:  
        (x, y, w, h) = cv2.boundingRect(approx)  
        aspect_ratio = float(w) / h  
        if 0.95 <= aspect_ratio <= 1.05:  
            return "Square", 2  # 正方体  
        else:  
            return "Cylinder", 3  # 圆柱体  
    elif len(approx) > 8:  
        return "Hemisphere", 4  # 半球  
    return "Unknown", 0  
  
  
def process_image(image):  
    # 缩放图像以将物体拉近  
    scale_percent = 150  # 缩放比例（150%）  
    width = int(image.shape[1] * scale_percent / 100)  
    height = int(image.shape[0] * scale_percent / 100)  
    dim = (width, height)  
    resized_image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)  
  
    # 裁剪中央区域  
    x_start = int(width * 0.2)  # 从图像宽度的20%位置开始  
    y_start = int(height * 0.2)  # 从图像高度的20%位置开始  
    x_end = int(width * 0.8)  # 到图像宽度的80%位置结束  
    y_end = int(height * 0.8)  # 到图像高度的80%位置结束  
    cropped_image = resized_image[y_start:y_end, x_start:x_end]  
  
    # 转换为HSV颜色空间  
    hsv = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)  
  
    # 红色的HSV范围  
    lower_red = np.array([0, 120, 70])  
    upper_red = np.array([10, 255, 255])  
    mask1 = cv2.inRange(hsv, lower_red, upper_red)  
  
    lower_red = np.array([170, 120, 70])  
    upper_red = np.array([180, 255, 255])  
    mask2 = cv2.inRange(hsv, lower_red, upper_red)  
  
    # 合并两个红色区域的掩码  
    mask = mask1 + mask2  
  
    # 使用形态学操作去除噪声  
    kernel = np.ones((5, 5), np.uint8)  
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  
  
    # 寻找轮廓  
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  
  
    detected_shapes = []  
  
    for contour in contours:  
        # 计算轮廓的近似  
        epsilon = 0.04 * cv2.arcLength(contour, True)  
        approx = cv2.approxPolyDP(contour, epsilon, True)  
  
        # 获取外接圆的中心和半径  
        (x, y), radius = cv2.minEnclosingCircle(contour)  
        if radius < 20:  # 忽略半径过小的噪声轮廓  
            continue  
  
        # 检查是否有相似半径的形状已被识别（防止重复识别）  
        if any(abs(radius - r) < 10 for _, _, r in detected_shapes):  
            continue  
  
        # 获取形状和编号  
        shape, code = identify_shape(approx)  
  
        if shape != "Unknown":  
            detected_shapes.append((shape, code, radius))  # 存储已识别的形状信息  
  
            M = cv2.moments(contour)  
            if M["m00"] != 0:  
                cX = int(M["m10"] / M["m00"])  
                cY = int(M["m01"] / M["m00"])  
                cv2.drawContours(cropped_image, [approx], -1, (0, 255, 0), 3)  
                cv2.putText(cropped_image, f"{shape} (ID: {code})", (cX - 50, cY - 50),  
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)  
                print(f"识别到 {shape}，编号: {code}")  
  
    return cropped_image  
  
  
def main():  
    # 打开摄像头（0 表示第一个摄像头）  
    cap = cv2.VideoCapture(0)  
  
    if not cap.isOpened():  
        print("无法打开摄像头")  
        return  
  
    while True:  
        # 读取摄像头帧  
        ret, frame = cap.read()  
        if not ret:  
            print("无法读取摄像头帧")  
            break  
  
        # 处理图像并识别物体  
        result_image = process_image(frame)  
  
        # 显示结果  
        cv2.imshow("Result", result_image)  
  
        # 按 'q' 键退出  
        if cv2.waitKey(1) & 0xFF == ord('q'):  
            break  
  
    # 释放摄像头资源  
    cap.release()  
    cv2.destroyAllWindows()  
  
  
if __name__ == "__main__":  
    main()
```

#### i. Aruco tag识别

```python
def detect_aruco_tag(frame):  
    # 定义字典和检测器参数  
    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)  # 使用6x6, 250种类的标签  
    parameters = aruco.DetectorParameters_create()  
  
    # 将图像转换为灰度图  
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  
  
    # 检测ArUco标记  
    corners, ids, _ = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)  
  
    # 如果检测到了ID标签  
    if ids is not None:  
        for i in range(len(ids)):  
            tag_id = ids[i][0]  
            print(f"识别到ArUco标签ID: {tag_id}")  
            # 绘制检测到的标记边框  
            aruco.drawDetectedMarkers(frame, corners, ids)  
            return True,tag_id,frame  
    else:  
        return False,None,None
```
# PART III 结果感想

在准备这个比赛的过程中，确实经历了一些技术上的挑战，也从中获得了不少收获。最初，我们的目标很明确：通过网络流传输实现稳定、实时的图像采集，同时保证多摄像头场景下的扩展性。然而，真正动手实现时才发现，理论和实践之间的差距远不止纸面上看起来那么简单。

首先，UDP 视频流的接入是一个难点。UDP 的不可靠性决定了我们必须在丢包、延迟、甚至是画面卡顿中找到一个平衡点。这部分调试花费了相当长的时间，但也因此让我们对视频流的传输机制有了更深的理解。最终通过使用 GStreamer 和 OpenCV 的结合，我们找到了一套既简单又灵活的方案，这也是对网络协议和多媒体处理的一次综合应用。

其次，多线程与队列的设计是另一个重要的技术环节。最初考虑的单线程方案在性能和实时性上表现不佳，尤其是在多摄像头场景下，图像处理的瓶颈非常明显。因此，我们引入了多线程和队列的架构，让图像采集与处理并行进行。这一设计看似简单，但在调优过程中，我们逐渐体会到数据同步、资源竞争这些并发编程中不可避免的问题，最终通过反复实验，找到了队列容量、线程调度的最佳组合。

当然，代码的最终实现并非完美无缺，但它在稳定性、实时性和可扩展性方面达到了我们最初的预期。这个过程中，我们不仅仅是在完成任务，更是对自己技术认知的一个深化。那些调试过程中出现的意外、陷入瓶颈时的思考，最终转化为解决方案的成就感，都是值得铭记的。

回顾整个开发过程，虽然技术上有过不少波折，但每一次困难的解决都伴随着认知的提升。项目结束时的那一刻，我对自己代码背后的每一行逻辑都有了更深刻的理解，也更清楚地认识到如何在复杂系统中找到效率与稳定性的平衡。或许这些感受在别人看来很普通，但对我而言，这次经历是一次实打实的技术磨练，收获的不仅仅是功能上的实现，更是一种“技术要为需求服务”的清晰认识。

总之，这次的开发体验让我更加坚定，技术上的每一步积累都不会白费，每一个看似简单的功能背后都蕴含着复杂的思考与权衡，只有脚踏实地，最终的成品才真正有价值。