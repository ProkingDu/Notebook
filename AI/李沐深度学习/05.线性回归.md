
## 线性回归
### 线性模型


给定一个输入：
$$
x = [x_{1},x_{2},\dots,x_{n}]^T
$$

线性模型有一个n维的权重（一般和输入特征数相同）和一个常数偏差：
$$
w = [w_{1},w_{2},\dots,w_{n}]^T,b
$$

线性模型计算输出的值是输入的加权和：
$$
y = w_{1}x_{1}+w_{2}x_{2}+\dots+w_{n}x_{n}+b
$$

将下线性模型转为向量计算，即为权重向量w与输入向量x进行内积加上偏差b。
$$
y=<w,x>+b
$$

线性模型可以视作单层神经网络：
![小杜的个人图床](http://src.xiaodu0.com/2024/09/24/e415ccb2afb17d7db653171fafa46027.png)
## 衡量预估质量

假设y为真实值，$\hat{y}$ 为预估值，则有真实值与预估值之间的**平方误差**：

$$\ell(y,\hat{y}) = \frac{1}{2}(y - \hat{y})^2$$这里有个二分之一的意义是方便在求导时使系数化为1.

### 训练损失


将上述的平方误差的预测值表达为线性模型的公式，得到预测损失关于输入x、权重w、偏差b的函数：
$$
 \ell(X,y,v,b) \equiv \frac{1}{2n} \sum_{i=1}^{n} (y_i - \langle x_i, v \rangle - b)^2 \equiv \frac{1}{2n} || y - Xw - b || 
$$
他的意义是将每一个输入的预测的平方误差求和之后求均值，最右边的公式是通过向量的L2范数表示。

**注意：每个样本的权重是不一样的，因此这里的w是权重向量。**

### 最小化损失

最小化损失实际上就是通过训练损失函数

