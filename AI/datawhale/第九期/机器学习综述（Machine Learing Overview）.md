
## 一、机器学习的发展


机器学习（Machine Learning）的各个阶段发展历程列表如下。

| **时间段**                                  | **机器学习理论**                                                                                                                                         | **代表性成果**                                                                                     |     |
| ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | --- |
| 二十世纪五十年代初                                | 人工智能研究处于推理期                                                                                                                                        | A. Newell和H. Simon的“逻辑理论家”（Logic Theorist）程序证明了数学原理，以及此后的“通用问题求解”（General Problem Solving）程序。 |     |
| 已出现机器学习的相关研究                             | 1952年，阿瑟·萨缪尔（Arthur Samuel）在IBM公司研制了一个西洋跳棋程序，这是人工智能下棋问题的由来。                                                                                        |                                                                                               |     |
| 二十世纪五十年代中后期                              | 开始出现基于神经网络的“连接主义”（Connectionism）学习                                                                                                                 | F. Rosenblatt提出了感知机（Perceptron），但该感知机只能处理线性分类问题，处理不了“异或”逻辑。还有B. Widrow提出的Adaline。             |     |
| 二十世纪六七十年代                                | 基于逻辑表示的“符号主义”（Symbolism）学习技术蓬勃发展                                                                                                                   | P. Winston的结构学习系统，R. S. Michalski的基于逻辑的归纳学习系统，以及E. B. Hunt的概念学习系统。                            |     |
| 以决策理论为基础的学习技术                            |                                                                                                                                                    |                                                                                               |     |
| 强化学习技术                                   | N. J. Nilson的“学习机器”。                                                                                                                               |                                                                                               |     |
| 统计学习理论的一些奠基性成果                           | 支持向量，VC维，结构风险最小化原则。                                                                                                                                |                                                                                               |     |
| 二十世纪八十年代至九十年代中期                          | 机械学习（死记硬背式学习）  <br>示教学习（从指令中学习）  <br>类比学习（通过观察和发现学习）  <br>归纳学习（从样例中学习）                                                                             | 学习方式分类                                                                                        |     |
| 从样例中学习的主流技术之一：（1）符号主义学习  <br>（2）基于逻辑的学习  | （1）决策树（decision tree）。  <br>（2）归纳逻辑程序设计（Inductive Logic Programming, ILP）具有很强的知识表示能力，可以较容易地表达出复杂的数据关系，但会导致学习过程面临的假设空间太大，复杂度极高，因此，问题规模稍大就难以有效地进行学习。 |                                                                                               |     |
| 从样例中学习的主流技术之二：基于神经网络的连接主义学习              | 1983年，J. J. Hopfield利用神经网络求解“流动推销员问题”这个NP难题。1986年，D. E. Rumelhart等人重新发明了BP算法，BP算法一直是被应用得最广泛的机器学习算法之一。                                              |                                                                                               |     |
| 二十世纪八十年代是机器学习成为一个独立的学科领域，各种机器学习技术百花初绽的时期 | 连接主义学习的最大局限是“试错性”，学习过程涉及大量参数，而参数的设置缺乏理论指导，主要靠手工“调参”，参数调节失之毫厘，学习结果可能谬以千里。                                                                           |                                                                                               |     |
| 二十世纪九十年代中期                               | 统计学习（Statistical Learning）                                                                                                                         | 支持向量机（Support Vector Machine，SVM），核方法（Kernel Methods）。                                        |     |
| 二十一世纪初至今                                 | 深度学习（Deep Learning）                                                                                                                                | 深度学习兴起的原因有二：数据量大，机器计算能力强。                                                                     |     |

## 二、机器学习的分类

机器学习大致可以分为四种类型：
1. **监督学习**
2. **无监督学习**
3. **半监督学习**
4. **强化学习**

### 2.1 监督学习

从**给定的训练数据集**中学习出一个函数（模型参数），当新的数据到来时，可以**根据这个函数预测结果**。**监督学习的训练集要求包括输入输出，也可以说是特征和目标**。训练集中的目标是由人标注的。**监督学习就是最常见的分类（注意和聚类区分）问题**，通过已有的训练样本（即**已知数据及其对应的输出**）去训练得到一个最优模型（**这个模型属于某个函数的集合**，**最优表示某个评价准则下是最佳的**），再利用这个模型将所有的输入映射为相应的输出，**对输出进行简单的判断从而实现分类的目的**。也就具有了对未知数据分类的能力。监督学习的目标往往是让计算机去学习我们已经创建好的分类系统（模型）。

监督学习是训练神经网络和决策树的常见技术。这两种技术高度依赖事先确定的分类系统给出的信息，对于**神经网络，分类系统利用信息判断网络的错误，然后不断调整网络参数**。对于**决策树，分类系统用它来判断哪些属性提供了最多的信息**。

总结：监督学习需要有人为提供的训练数据集，其中包括特征和目标，监督学习常用语分类和预测问题。

### 2.2 无监督学习

**与监督学习不同，无监督学习并非告诉计算机怎么做，而是让计算机自己学习怎么做。**

无监督学习输入的数据没有标记，并且输出没有明确的结果，样本分类也是不确定的，需要通过样本之间的相似性对样本集进行分类（聚类，clustering）。试图使 **类内差距最小化，类间差距最大化** 通俗点将就是实际应用中，不少情况下**无法预先知道样本的标签**，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。

典型的无监督学习方法是奖励和惩罚机制，让计算机自行决定如何做，在指导agent时不为其指定明确的分类，而是在成功时采用某种形式的激励记录。这种问题通常存在于决策机制的框架里，因为**它的目标不是为了产生一个分类系统，而是做出最大回报的决定**，这种思路很好的概括了现实世界，agent可以对正确的行为做出激励，而对错误行为做出惩罚。

### 2.3 半监督学习

半监督学习是监督学习和非监督学习的结合，其**在训练阶段使用的是未标记的数据和已标记的数据**，**不仅要学习属性之间的结构关系，也要输出分类模型进行预测。**

半监督学习旨在通过少量的有标签数据和大量的无标签数据来对模型进行训练，通过**充分利用无标签数据来对提升模型的泛化能力，同时通过有标签数据来引导模型确定正确的决策边界。**

### 2.4 强化学习

强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一，用于**描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题.**

强化学习中的**核心概念**:
    - **代理（Agent）**：强化学习中的决策者，它通过观察环境状态并采取行动来学习最优策略。
    - **环境（Environment）**：代理所存在的外部条件，能够对代理的行动提供反馈（奖励或惩罚）。
    - **状态（State）**：描述环境的一种方式，通常包含代理做出决策所需的全部信息。
    - **动作（Action）**：代理在给定状态下可以采取的行为。
    - **奖励（Reward）**：环境对代理行动的反馈，通常是标量值，表示该行动对达到目标的好坏程度。


## 三、机器学习模型

机器学习的基本构成有如下三个方面：
**机器学习 = 数据（data）+ 模型（model）+ 优化方法（optimal strategy）**

![小杜的个人图床](http://src.xiaodu0.com/2024/06/15/769cd2a7047ecf0aee0e765745edba19.png)
<center>图1 机器学习模型图</center>

<img src=https://nanjunxiao.github.io/img/A%20few%20useful%20things%20to%20know%20about%20machine%20learning.jpg>

<center>图2 机器学习注意事项</center>

## 四、常见机器学习算法

### 4.1 线性算法（Linear Algorithms）
线性算法主要指基于**线性关系进行分析或者预测**的方法，这类算法的核心思想是**通过建立线性模型来描述自变量（特征）与因变量（目标变量）之间的关系**。

> **线性关系**：
> 线性关系指两个变量之间存在直线的关系，其中一个变量（自变量）的变化会导致另一个变量（因变量）以**恒定的速率**变化，线性关系可以通过直线方程来表示，其中的常数项（截距）和斜率（系数）描述了变量之间的相互关系。

> **非线性关系**
> 简单来说，两个变量之间的关系是一次函数的关系，即图像是直线的，就称为线性关系，而非线性关系就是两个变量之间的关系不是一次函数的关系，图像不是直线的。


线性算法主要包括四个：
1. 线性回归算法（Linear Regression）
2. 套索回归（Lasso Regression）
3. 岭回归（Ridge Regression）
4. 逻辑回归算法（Logistic Regression）

#### 4.1.1 线性回归算法


线性回归是一种基本的**预测建模技术**，他的目标是在自变量和因变量之间找到一条最佳直线，使得这条直线上的预测值与真实值之间的误差最小。

**线性回归的基本假设：**
1. **线性关系**：进行线性回归建模的前提，自变量和因变量之间存在线性关系。
2. **独立同分布**：观测值是独立同分布的。
3. **无多重共线性**:即自变量之间不存在多重共线性（自变量不应高度相关）
4. **误差项的正态性**：误差项（即，真实值与预测值之间的差异）服从正态分布。
5. **同方差性**：误差项的方差是恒定的，不随自变量的变化而变化。

> **独立同分布**：
> 独立同分布是概率统计论中的一个重要概念，指随机过程中的变量取值都是随机的，这些随机变量服从同一分布并且取值相互独立不影响，则称为独立同分布。（**同一分布、取值独立。**）

**线性回归的基本模型：**
线性回归的基本模型可以表示为：
***y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ***

其中：
- y 是因变量（响应变量、目标）
- x₁, x₂, ..., xₙ 是自变量（预测变量、特征）
- β₀ 是截距项
- β₁, β₂, ..., βₙ 是回归系数（也称为斜率），它们表示每个自变量对因变量的影响程度


**线性回归的意义：**
线性回归是解决回归问题中最简单也是最常用的一种算法，通过建立自变量与因变量之间的线性关系模型可以通过给定的自变量值预测因变量值。
也就是说，线性回归用于解决预测和回归的问题。

**Pytorch实现：**
```python
import torch  
import torch.nn as nn  
import torch.optim as optim  
import numpy as np  
import matplotlib.pyplot as plt  
  
# 设定随机数种子以便结果可复现  
torch.manual_seed(0)  
  
# 生成模拟数据  
np.random.seed(0)  
x_train = np.random.rand(100, 1) * 10  # 100个样本，特征值在0到10之间  
y_train = 2 * x_train + 3 + np.random.randn(100, 1) * 0.3  # 通过自变量产生的标签值  
  
# 将numpy数组转换为PyTorch张量  
x_train_tensor = torch.from_numpy(x_train).float()  
y_train_tensor = torch.from_numpy(y_train).float()  
  
  
# 定义线性回归模型  
class LinearRegression(nn.Module):  
    def __init__(self, input_dim, output_dim):  
        super(LinearRegression, self).__init__()  
        self.linear = nn.Linear(input_dim, output_dim)  
  
    def forward(self, x): # 前向传播  
        out = self.linear(x)  
        return out  
  
  
  
# 初始化模型  
input_dim = 1    # 线性回归算法的输入输出维度都是1  
output_dim = 1  
model = LinearRegression(input_dim, output_dim)  
  
criterion = nn.MSELoss()    # 计算均方误差的损失函数  
learning_rate = 0.01   # 学习率  
# 创建SGD优化器用于自动更新参数，其中model.parameters包含模型中所有可训练参数的迭代器，lr是学习率的缩写，指定参数更新的步长。  
optimizer = optim.SGD(model.parameters(), lr=learning_rate)  
  
# 训练模型  
num_epochs = 100   # 指定参数更新次数  
for epoch in range(num_epochs):  
    # 前向传播  
    outputs = model(x_train_tensor)  
    # 通过输出和标签值计算损失值  
    loss = criterion(outputs, y_train_tensor)  
  
    # 反向传播和优化  
    optimizer.zero_grad()  # 清零梯度缓存  
    loss.backward()  # 反向传播，计算梯度  
    optimizer.step()  # 使用梯度下降更新权重  
  
    if (epoch + 1) % 10 == 0:  
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')  
  
  
  
# 获取模型的参数  
print('Model parameters:')  
for name, param in model.named_parameters():  
    print(f"    Name: {name}, Value: {param.data.numpy()}")
```

#### 4.1.2 套索回归（Lasso回归）

**Lasso回归是什么：**

Lasso回归是一种是一种广泛使用的**回归分析方法**，尤其在处理具有多重共线性或高维数据时表现出色。

**Lasso回归的原理：**

Lasso回归通过在目标函数中引入L1正则化项（即**变量系数的绝对值之和**），对系数的绝对值进行惩罚，使得一些不重要的系数值变为零。
![小杜的个人图床](http://src.xiaodu0.com/2024/06/16/62ba35d464328a5566639b6c52d8b981.png)

在Lasso回归中，λ是一个关键的参数，其值的大小直接影响到最终模型的表现。当λ为0时，Lasso回归就退化为普通的最小二乘回归。随着λ值的增加，越来越多的系数被压缩为零，这有助于特征选择和降低模型复杂度。然而，如果λ过大，它可能会导致模型过于简单，从而影响模型的预测能力。因此，选择一个合适的λ值是实现最佳模型性能的关键。

总的来说，Lasso回归就是在目标函数中引入了系数绝对值作为惩罚参数来达到降低模型复杂度和特征选择的目的。

**Lasso回归的作用：**

Lasso回归主要有两个重要的作用：**变量选择和模型简化**。
首先是变量选择，Lasso回归通过变量系数绝对值作为惩罚来使不重要的系数值变为零，从而只保留重要的系数项即变量。
另一方面，通过选择重要的变量和压缩系数能够有效的降低模型的复杂度。
同时通过保留重要系数项能够显示出数据集中的主要特征，达到特征选择的目的。

#### 4.1.3 岭回归（Rideg Regression）

**岭回归是什么？**
岭回归是一种**改良的最小二乘估计法**，通过放弃最小二乘法的无偏性，以**损失部分信息、降低精度为代价**获得回归系数，它是更为符合实际、更可靠的回归方法，对存在离群点的数据的拟合要强于最小二乘法。

岭回归也被称为**L2正则化线性回归**或**Tikhonov正则化**，是一种用于**处理共线性数据**（即特征之间高度相关的数据）和**防止过拟合**的统计学方法。

**岭回归的原理：**
线性回归模型的目标函数：**J(β)=∑(y−Xβ)<sup>2</sup>**
为了保证回归系数β \betaβ可求，岭回归模型在目标函数上加了一个L2范数的惩罚项:
<center><b>J(β)=∑(y−Xβ)2+λ∣∣β∣∣22</b></center>
<center><b>=∑(y−Xβ)2+∑λβ2</b></center>


其中λ为非负数，λ越大，则为了使J(β)最小，回归系数β就越小。

 L2范数惩罚项的加入使得(XTX+λI)满秩，保证了可逆，但是也由于惩罚项的加入，使得回归系数β的估计不再是无偏估计。所以**岭回归是以放弃无偏性、降低精度为代价解决病态矩阵问题的回归方法。**
单位矩阵I的对角线上全是1，像一条山岭一样，这也是岭回归名称的由来。

**岭回归的应用：**
- 岭回归在处理共线性数据、防止过拟合和提高模型泛化能力方面有着广泛的应用。
- 在一些复杂的模型中，如深度神经网络，岭回归也可以用于**防止过拟合。**


#### 4.1.4 逻辑回归算法


**逻辑回归是什么？**
逻辑回归（Logistic Regression）是一种用于**解决二分类（0 or 1）问题**的机器学习方法，用于**估计某种事物的可能性。**
它是一种线性分类器，基于线性回归模型，但通过引入非线性函数（如sigmoid函数）进行转换，将输出限制在(0,1)范围内，从而用于分类。

**逻辑回归的算法流程：**
- 首先，将输入的每一项与对应权重相乘，得到的结果进入**sigmoid**函数进行非线性处理，将输出限制在(0,1)范围内。
- 然后，利用输出值和实际值求出代价函数，并对代价函数求偏导求解出梯度，进而更新权重。
- 重复上述过程，直到模型收敛或达到预设的迭代次数。

**逻辑回归的数学原理：**

由于逻辑回归是基于线性回归的，首先给出线性回归的公式：
<center><big><b>f(x)=w′x+b</b></big></center>

其中，w 是权重向量，x 是特征向量，b 是偏置项（有时为了简化计算，可以将偏置项合并到权重向量中，即令 x′=[1,x]，w′=[b,w]）。

sigmoid函数将线性回归的输出值映射到(0, 1)区间，从而得到样本属于某一类别的概率。
**sigmoid函数的公式为：**
<center><big><b>g(z)=1/(1+e<sup>−z</sup>​)</b></big></center>
其中，z 是线性回归的输出值。

结合线性回归模型和sigmoid函数，逻辑回归的模型可以表示为：
<center><big><b>hθ​(x)=g(f(x))=1/(1+e−(w′x+b)​)</b></big></center>

或者，当偏置项合并到权重向量中时：
<center><img src="http://src.xiaodu0.com/2024/06/17/774f044fa9037219d0a10d6c6abcb3b6.png"></center>

其中，θ 是包含偏置项和权重的参数向量，hθ​(x) 表示样本 x 属于正类的概率。

在逻辑回归中，我们通常将阈值设置为0.5，即当 hθ​(x)≥0.5 时，将样本 x 划分为正类，否则划分为负类。

逻辑回归也可以用于表示二分类问题的概率，即：
<center><big><b>P(y=1∣x;θ)=hθ​(x)</b></big></center><center><big><b>P(y=0∣x;θ)=1−hθ​(x)</b></big></center>


其中，y 是样本的类别标签（0或1），x 是样本的特征向量，θ 是模型参数。

**逻辑回归的总结：**
总的来说，逻辑回归模型结合线性回归模型和sigmoid函数，将线性回归的输出值通过sigmoid函数转化为概率值，进而实现二分类问题（是或者不是）。通常将阈值设置为0.5，当概率值大于0.5则认为样本是正类，否则为负类。

### 4.2 决策树（Decision Tree）

决策树（Decision Tree）是一种常用的**监督学习算法**，用于**分类和回归**任务。它采用树形结构，其中**每个内部节点表示一个特征上的测试**，**每个分支代表该特征的一个可能值（或值的范围**），而**每个叶节点则代表一个类别（对于分类任务）或一个具体的数值（对于回归任务）**。

#### ID3

**基本原理**：
ID3算法的两个核心概念是信息熵和信息增益。
**信息熵：** 信息熵指数据集中数据的不确定性，数据不确定性越大，信息熵越大，反之信息熵越小，数据的不确定性越小。
**信息增益：** 信息增益是指在给定的属性条件下计算的减少信息不确定性（即熵减）的程度，信息增益越大，则对数据处理的能力越强，信息熵减少的程度越大。
ID3的核心思想是选择最能降低数据不确定的属性来划分，直到所有的数据都属于同一类别。


**ID3的基本步骤：**

1. **计算信息增益：** 对于数据集的每一个属性，计算其信息增益，也就是减少信息不确定性的程度。
2. **划分子集：** 将计算得到的具有最大信息增益的属性作为划分点，将数据集划分为更小的子集。
3. **递归构建：** 重复上述步骤，对每个具有最大信息增益的子属性作为划分点进一步划分数据集，直到满足停止条件。（例如所有数据已经属于同一类，或者已经没有可供划分的最小子集，或者子集大小小于某个阈值。）


**决策树结构**：
在ID3算法中，**每个节点表示一个属性，每个分支表示一个属性值，每个叶子节点表示一个类别。**
![小杜的个人图床](http://src.xiaodu0.com/2024/06/20/290434fa5fa33133cba83fc6fa6beedb.png)

ID3算法的分类过程是：从根节点开始，根据样本在属性上的取值沿着决策树往下遍历，直到找到一个叶子节点，这个叶子节点表示的类别即为样本所属的类别。


**总结：**

ID3算法是一种**基于信息熵和信息增益**的决策树学习算法，通过选择最能降低数据不确定性的属性来构建决策树。虽然ID3算法在某些情况下**可能存在过拟合、无法处理连续特征**等缺点，但其原理简单、易于理解和实现的特点使得它在机器学习领域仍然具有广泛的应用价值。

#### C4.5

**C4.5算法是在ID3算法的基础上构建的基于信息熵和信息增益的决策树算法。**

与ID3不同的是，**C4.5算法将信息熵定义为数据的纯度，而信息增益则是某个属性值对数据集的划分带来的数据纯度的提升。**

对于每个属性，C4.5会计算其信息增益，并选择信息增益最大的属性作为当前节点的划分属性。

C4.5能够处理连续属性和缺失属性。对于连续属性，C.4.5通过二分法进行处理，对于缺失属性，则会考虑所有取值，并且依据缺失值所占比例计算信息增益。

为了避免过度拟合，C4.5在决策树构建完成后执行剪枝，去除一些不必要的叶子节点，提高模型的泛化性能。

C4.5决策树算法广泛应用于**分类问题**，例如医学诊断、金融风险评估、客户分类等领域。

#### CART(Classification and regression Tree，分类和回归树)

CART（Classification and Regression Trees）是一种决策树学习算法，它可以用于分类和回归问题。CART算法由Leo Breiman, Jerome Friedman, Richard Olshen, 和Charles Stone四人提出。CART与C4.5算法类似，但CART有一些关键的不同点，尤其是在构建树和剪枝的策略上。


**CART的主要特点：**

1. **二分递归分割**：CART决策树总是将父节点划分为两个子节点，即**CART是二叉树**。在分类问题中，CART通过选择最优特征以及该特征的最优切分点（阈值）进行二分类；在回归问题中，CART使用特征的某个值作为切分点，将数据集划分为两部分。
2. **使用Gini指数（分类）或平方误差（回归）**：CART分类树使用Gini指数作为选择最佳划分属性的标准，而C4.5使用信息增益或增益率。对于回归树，CART使用平方误差最小化准则
3. **剪枝策略**：CART使用一种称为**代价复杂度剪枝**（Cost-Complexity Pruning）的方法，该方法通过生成一系列复杂度不同的树，并使用交叉验证选择最优的树。
4. **可以处理数值型和类别型特征**：CART算法可以处理数值型和类别型特征，但类别型特征需要预先进行编码（如独热编码）。

**CART算法流程**：

1. **特征选择：**根据数据集的特征（分类或者回归）来选择最优的划分标准（依据gini系数或者平方误差）
2. **生成决策树**：通过递归将数据集不断划分为纯度更高的子集，直到满足停止条件（所有样本属于同一类别，或者特征用完，或者样本数小于特定阈值等。）
3. **决策树剪枝：** 通过代价复杂度的方法进行剪枝，生成一系列复杂度不同的子树，并选择值最优的子树作为最终的决策树。


###  4.3 SVM（Support Vector Mechine，支持向量机）

**支持向量机的定义：**
支持向量机（SVM）是一类**按监督学习（supervised learning）方式对数据进行二元分类的广义线性分类器**（generalized linear classifier）。其**决策边界是对学习样本求解的最大边距超平面**（maximum-margin hyperplane）。

**基本原理**：

SVM的基本原理或者说处理步骤有四个方面：
首先，寻找超平面，其次，最大化间隔，随后确定支持向量， 最后处理非线性数据。

1. **寻找超平面**：SVM的基本原理是寻找一个超平面将数据分别两个类别。这个超平面在二维中表示为一条直线，在三维中表示为一个平面，依次推到更高维
2. **最大化间隔**：这个寻找到的超平面会被最大会为两个类别的间隔，即使得距离超平面最近的样本点到超平面的距离要尽可能的远。
3. **支持向量**：只有离超平面最近的样本点（称为支持向量）会影响决策边界的确定，其他样本点对决策边界没有影响。
4. **处理非线性数据**：当数据非线性可分时，SVM可以通过引入核函数（kernel function）将数据映射到高维空间，使得数据在高维空间中变得线性可分。

**解决的问题：**

SVM既可以解决线性问题，也可以解决非线性问题，既可以用于分类，也可以用于回归。
- **线性分类**：当数据集是线性可分时，SVM通过求解一个二次规划问题来找到最优超平面。
- **非线性分类**：当数据集不是线性可分时，SVM引入核函数将原始数据映射到高维空间，使其在新空间中变得线性可分。

**应用场景：**

SVM在许多领域都有广泛的应用，包括但不限于：

1. **文本分类**：如垃圾邮件过滤、情感分析、主题分类等。
2. **图像识别**：如手写数字识别、人脸识别、物体检测等。
3. **生物信息学**：如基因表达数据分析、蛋白质结构预测、药物设计等。
4. **金融预测**：如股票价格预测、信用评分、风险评估等。


****
### Date：6月25-7月1日
****

### 4.3 朴素贝叶斯算法（Naive Bayes Algorithms）

#### 4.3.1 Naive Bayes

Naive Bayes 是一种**基于贝叶斯定理与特征条件独立假设的分类方法**。它假定给定类别下，特征之间是相互独立的。这种假设虽然在实际应用中可能并不总是成立，但朴素贝叶斯分类器在许多情况下都能取得相当好的效果。

##### 概率论基础回顾：

**（1）条件概率**

就是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”。

**（2）联合概率**

可以简单的理解为事件A与事件B都发生的概率，记为P(AB)或P(A, B)。

此处就有  **P(A, B) = P(A|B) * P(B)**

**若事件A与事件B独立，则有 P(A, B) = P(A) * P(B)**，这也说明了此时 P(A|B) = P(A)。

**（3）全概率**

如果事件B1，B2，B3，…，Bn 构成一个完备事件组，即它们两两互不相容，其和为全集；并且P(Bi)大于0，则对任一事件A有：

P(A)=P(A|B1)*P(B1) + P(A|B2)*P(B2) + ... + P(A|Bn)*P(Bn)

##### **贝叶斯定理：**

**贝叶斯定理即在已知P(A|B)的情况下求P(B|A)。**

贝叶斯定理的公式：
![小杜的个人图床](http://src.xiaodu0.com/2024/06/26/ad3ca8f499600f3c62ba0c02ffcec783.png)
即在A发生前提下B发生的概率等于在B发生的前提下A发生的概率与B的概率的积除以A发生的概率。
其中：

**P(B)**：为先验概率，即在**A**事件发生之前，对**B**事件发生概率的预判。
**P(A|B)**:为后验概率，即在**A**事件发生之后，对**B**事件发生概率的重新评估。
**P(A|B)/P(A)**:为可能性函数，是一个调整因子，使得预估概率更加接近真实概率。
**如果调整因子>1，则表示先验概率被增强，事件A发生的可能性变大。**
**如果调整因子=1，则表示事件B对判断事件A发生的概率没有帮助。**
**如果调整因子<1，则表示先验概率被削弱，事件A发生的可能性变小。**

其简单推倒如下：
由于P(AB)=P(A|B)P(B),
同理，P(AB)=P(B|A)P(A)
则，P(B|A)P(A)=P(A|B)P(B)
因此：
P(B|A)=P(A|B)P(B)/P(A)

简单的例子：
> 现有校准过的枪5把，没校准过的3把。现在某人用校准过的枪打靶中靶概率为0.8，用没校准过的枪中靶概率只为0.3。现在已知拿起一把枪打靶中靶了，请问这个枪是校准过的枪的概率？
> 
> 令A=命中,B1为选用校准过的枪，B2为未校准的枪。
> 则 P(B1)=3/8 P(B2)=5/8 P(A|B1)=0.8 P(A|B2)=0.3
> 同时，中靶（条件）的枪是校准过得枪（事件）的概率为：P(B1|A)
> 由全概率公式:
> P(A)=P(A|B1)P(B1)+P(A|B2)P(B2)=8/10+3/8+3/10+5/8=49/80
> 再由贝叶斯定理：
> P(B1|A)=P(A|B1)P(B1)/P(A)=40/49


##### 朴素贝叶斯分类问题

朴素贝叶斯（naive bayes）解决的是分类的问题，在分类问题中，我们要求解的是**给定特征 X** 下，**类别 Y 的概率 P(Y∣X)**，亦即特征X输入类别Y的条件概率。
根据贝叶斯定理，我们有：

***P(Y∣X)=P(X)P(X∣Y)P(Y)​***


由于 P(X) 对于所有类别都是相同的，因此在比较不同类别的 P(Y∣X) 时，可以忽略 P(X)。所以，**朴素贝叶斯分类器选择 P(Y)P(X∣Y) 最大的类别作为预测结果。**


##### 贝叶斯推断

贝叶斯定理的许多应用之一就是贝叶斯推断，**一种特殊的统计推断方法，随着信息增加，贝叶斯定理可以用于更新假设的概率。** 在决策理论中，贝叶斯推断与主观概率密切相关，通常被称为“Bayesian probability(贝叶斯概率)”。

贝叶斯推断根据 prior probability(先验概率) 和统计模型导出的“likelihood function(似然函数)”的结果，再由贝叶斯定理计算 posterior probability(后验概率)：

$$P(H|E)=\frac{P(E|H)P(H)}{P(E)}$$
其中：
- P(H) – 已知的先验概率
- P(H|E) – 我们想求的后验概率，即在B事件发生后对于事件A概率的评估
- P(E|H) – 在事件H下观测到E的概率
- P(E) – marginal likelihood(边际似然)，对于所有的假设都是相同的，因此不参与决定不同假设的相对概率
- $\frac{{P(E|H)}}{P(E)}$ – likelihood function(可能性函数)，这是一个调整因子，通过不断的获取信息，可以使得预估概率更接近真实概率

整个公式可以解释为：**某个推断的后验概率等于先验概率乘以可能性函数。**


**贝叶斯推断的示例：**
例如有两个篮子，一号篮子里面装有40个葡萄个20个荔枝，二号篮子中装有葡萄和荔枝各30个，求随机挑选一个篮子，再在这个篮子中挑选一个水果，求挑选在一号篮子里挑选到荔枝的概率。

显然这里的先验概率是挑选到一号篮子，即P(H1)=0.5,P(H2)=0.5 后验概率是在一号篮子里挑选到荔枝，即在拿到水果前，选到一号篮子的概率是先验概率，而在选到篮子之后取到对应的水果则是后验概率。

设P(H)为挑选到每个篮子的概率，则P(H1)=P(H2)=0.5
设P(E)为挑选到荔枝的概率，则在一号篮子里面挑选到荔枝的概率P(E|H1)=1/3

则在篮子里挑选到荔枝的概率为：
$${P(H_{1}|E)}=\frac{P(E|H_{1})P(H_{1})}{P(E)}$$
由全概率公式得以得出：
$$P(E)=P(E|H_{1})P(H_{1})+P(E|H_{2})+P(H_{2})$$
因此：
$$
\begin{align*}
\\{P(H_{1}|E)}&=\frac{P(E|H_{1})P(H_{1})}{P(E)}
\\&=\frac{P(E|H_{1})(H_{1})}{P(E|H_{1})P(H_{1})+P(E|H_{2})+P(H_{2})}\\
\\&=\frac{{\frac{1}{3}+\frac{1}{2}}}{\frac{1}{3}+\frac{1}{2}+\frac{1}{2}+\frac{1}{2}}\\
\\&=\frac{\frac{5}{6}}{\frac{5}{6}+1}\\
\\&= \frac{5}{11}
\end{align*}
$$
##### 特征条件独立假设

这一部分是关于贝叶斯分类与其特征条件独立假设的原理推导。

贝叶斯分类的具体定义如下：
1. 给定待分类项$x=\{{a_{1},a_{2},a_{3},\dots,a_{n}}\}$，其中$a_{n}$表示x的特征属性
2. 有集合$C=\{{y_{1}},y_{2} ,y_{3},\dots ,y_{n}\}$ 其中$y_{n}$表具体的类别
3. 计算$P({y_{1}|x}),P(y_{2}|x),P(y_{3},x),\dots P(y_{n}|x)$
4. 若$P(y_{k}|x)=max(\{P({y_{1}|x}),P(y_{2}|x),P(y_{3},x),\dots P(y_{n}|x)\})$则$x\in y_{k}$


对于第三步的各个条件概率的计算，我们可以进行如下操作：
1. 找到一个已知分类的待分类项的集合，作为样本训练集
2. 统计得到每一个分类下各个特征属性的条件概率估计，
 ![](http://latex.codecogs.com/gif.latex?P%28a_1%7Cy_1%29,P%28a_2%7Cy_1%29,...,P%28a_m%7Cy_1%29;P%28a_1%7Cy_2%29,P%28a_2%7Cy_2%29,...,P%28a_m%7Cy_2%29;...;P%28a_1%7Cy_n%29,P%28a_2%7Cy_n%29,...,P%28a_m%7Cy_n%29)
 3. 如果各个特征属性是条件独立的，则根据贝叶斯定理有如下推导：
 $$
 P(y_{i}|x)=\frac{P(x|y_{i})P(y_{i})}{P(x)}
$$

由**全概率公式**可知，**分母P(x)对于所有的类别是一个常数**， 因此在推导概率的时候，只需要将分子最大化即可。又因为**各特征属性是条件独立**的，所以有：
$$
\begin{align*}
\\P(x|y_{i})&= P(a_{1}|y_{i})P(a_{2}|y_{i})P(a_{3}|y)\dots P(a_{n}|y_{i})P(y_{i})\\\\
\\&= P(y_{i})\prod_{j=1}^{n}P(a_{j}|y_{i})
\end{align*}
$$

给定训练数据集（X,Y），其中每个样本x都包括n维特征，即x=(x1,x2,x3,...,xn)，类集合含有k种类别，即y=(y1,y2,...,yk)。

如果现在来了一个新样本x，我们要怎么判断它的类别？从概率的角度来看，这个问题就是给定x，它属于哪个类别的概率最大。那么问题就转化为求解P(y1|x),P(y2|x),...,P(yk|x)中最大的那个，即求后验概率最大的输出：arg max ykP(yk|x)

而对于$P(y_{k}|x)$的求解，可以直接利用贝叶斯定理：
$$
P(y_{k}|x)=\frac{P(x|y_{k})P(y_{k})}{P(x)}
$$

根据全概率公式：
$$
\begin{align*}
P(y_{k}|x)&= \frac{P(x|y_{k})P(y_{k})}{P(x)}\\
&= \frac{P(x|y_{k})P(y_{k})}{\sum_{i=1}^{k}P(x|y_{k})P(y_{k})}\\
\end{align*}

$$

对于公式中的先验概率$P(y_{k})$ 根据训练集就可以简单的计算出来，即：
$$
P(y_{k})=\frac{1}{分类样本总数}
$$

而条件概率$P(x|y_{k})=P(x_{1},x_{2},\dots,x_{n}|y_{k})$
它的参数规模是指数数量级别的，假设第i维特征$x_{i}$可取值的个数有S个，类别取值个数为k个，那么参数个数为：$k\prod_{i=1}^{n}Si$个

**针对这个问题，朴素贝叶斯算法对条件概率分布作出了独立性的假设**，通俗地讲就是说假设各个维度的特征$x_{1},x_{2},x_{3},\dots,x_{n}$互相独立，在这个假设的前提上，条件概率可以转化为：

$$
P(x|y_{k})=P(x_{1},x_{2},x_{3},x_{4},\dots x_{n}|y_{k})=\prod_{i=1}^nP(x_{i}|y_{k})
$$


以上就是针对条件概率所作出的特征条件独立性假设，至此，先验概率$P(y_{k})$和条件概率$P(x|y_{k})$的求解问题就都解决了，进而进行后验概率$p(y_{k}|x)$的值。

将条件概率代入到后验概率的公式可得：
$$
\begin{align*}
P(y_{k}|x)&= \frac{P(x|y_{k})P(y_{k})}{P(x)}\\
&= \frac{P(y_{k})\prod_{i=1}^nP(x_{i}|y_{k})}{\sum_{k}P(y_{k})\prod_{i=1}^nP(x_{i}|y_{k})}\\
\end{align*}
$$

于是朴素贝叶斯分类器可以表示为：
![](https://img-blog.csdn.net/20180704172728577?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p3cWpveQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

因为对所有$y_{k}$，上式中的分母的值都是一样的**（为什么？注意到全加符号就容易理解了）** ，所以可以忽略分母部分，朴素贝叶斯分类器最终表示为：
![](https://img-blog.csdn.net/20180704184006160?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p3cWpveQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

