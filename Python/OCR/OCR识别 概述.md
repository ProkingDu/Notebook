
## 概述

OCR主要包括：

1. 检测到文字所在的位置（CTPN）
2. 识别文本区域内容（CRNN）

## CTPN

#### 关于CPTN

CTPN即Connectionist Text Proposal Netwok，文本检测本质也属于物体检测，但是文本和物理有简答的区别。

CTPN是在ECCV 2016提出的一种文字检测算法。CTPN结合CNN与LSTM深度网络，能有效的检测出复杂场景的横向分布的文字。

- 文本通常都是从左往右写的（水平），并且字之间的宽度都大致相同。
- 固定宽度，来检测文本高度即可，但是如果应变变长序列呢？
- 本质上还是RPN方法，可将检测的框拼在一起。

![小杜的个人图床](http://src.xiaodu0.com/2024/04/19/b8c1273ef3479d281cf61bb5c83c7be6.png)


检测框的宽度相等，将他们组成一个完整的区域，只需要知道高度即可。

#### CTPN网络架构

CTPN包含如下三个方面：

-  **通过VGG提取特征**

通过VGG提取特征，确定区域内是不是文本，得到的结果只有是和不是。


- **通过BLSTM融入上下文信息**

LSTM即**长短期记忆神经网络**，LSTM可用于时间序列的上下文分析。

**如果单纯通过VGG提取特征，当区域中没有文本，或者是只有文本的一小部分时，容易被忽略或者将这一区域视作另一个上下文**。

通过LSTM，将**提取特征的区域融入上下文的时序特征以避免区域因为特征不足而被误判**。

实际上CTPN更多的使用双向的LSTM即BLSTM，将检测的区域从首尾各比较一次，**最后得到的区域长度是原先区域的两倍。**


- **基于RPN完成检测**


- **综述**：

在上述通过VGG提取特征之后，通过BLSTM融入上下文，交给RPN完成检测，整个过程如下图所示：
![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/fc937cfb32305bf4c5b10d8a98e2cf21.png)

1. **VGG提取特征**：

假设输入N副图像，通过VGG提取特征，得到大小为**NxCxWxH**的一个5\*5图像特征映射（称为conv5 feature map）。之后在conv5上做3\*3的滑动窗口得到一个3\*3\*C的特征向量，其中C为图像通过卷积层处理后的输出通道数量，输出为**N\*9C\*H\*W**。

由于选框的高度是固定的，因此将NH作为样本batch，前面已经提到了这时候宽度应当是固定的。所以只需要将N和H作为样本变量即可。对特征映射进行重塑：**(NxH)x9CxW**

2. **BLSTM融入上下文**：

对特征映射重塑之后以batch为NH且最大时间长度Tmax=W的数据流输入BLSTM，BLSTM将特征以W为维度将特征构成一个时间序列，再经过Reshape重回原样：NHxWx256 -> Nx256xHxW，该特征即包括图像的空间特征，又包括LSTM学习到的特征。

3. **RPN检测**：

首先，在得道BLSTM的特征序列之后，通过卷积层FC进行二分类判断，即生成对当前的框内是前景还是背景的分数，由于有k个框需要检测， 所以返回的是**2k个scores**，这里的分数指框是背景的得分和框是前景的得分。

对于2k vertical coordinates，他的含义是框的垂直的坐标，这个数据是来自框的中心点和高度表示的，因此k个框也会得到**2k个回归**。

k个side-refinement，这部分主要是用来精修文本行的两个端点的，表示的是每个proposal的水平平移量。实际上每个小框的x是固定的，但是对于整个选框，在起始和结尾的x位置需要微调，只需要调整x的位置，而不需要调整起始和结尾的框的宽度，这里输出**k个边界调整**。



## CTPN细节概述

### VGG特征提取模块

在CTPN中使用的是VGG16网络。

**VGG16构成**：13个卷积层，5个池化层，3个全连接层组成。13+3 = 16，所以叫VGG16。  
5个池化层没有计入其中，是不做运算的。

VGG16构成图示：
![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/a237aee8d5262b19e9f8bf50a26b2753.png)

实际上在CTPN中，只需要用到输入、卷积层，得到卷积层对原始图像特征的池化之后的数据就不需要再进行全连接和输出了，而是直接将这个数据交给BLSTM进行上下文融入。

这一完整的步骤是，在输入原始图像，对原始图像进行卷积得到特征图之后，通过池化降低特征图的维度，在VGG16中有五个池化层，实际上第一个池化层是经由原始图像得到的第一个特征图，然后在接下来进行四次池化，每次池化使原始的特征图在二维上缩小为原来的二分之一倍，同时在深度上变为原来的二倍，经**过四次池化操作之后，特征图在二维上缩小为1/2^4即1/16倍，在深度上成为16倍，即池化后的特征图一个像素点对应原先的16个像素点。**


### 竖直anchor定位文字位置

在CTPN中使用竖直定位的方式对文字选框进行定位，anchor即参照点，在CTPN中由于宽度是固定的，高度是变化的，因此采用一组（10个）等宽度的anchor用于定位文字位置。

![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/17a57f2dfc0e648b0858f821c76b9271.png)

由于CTPN使用VGG16算法，在经过四次池化之后，conv5特征图中的宽高都是原始特征图的1/16。


同时fc与原始的conv5的宽高都相等。


![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/2069351007596d521bdf3b7c018cfaff.png)
如上图所示，CTPN为fc即卷积后的特征图每个像素分配了10个上诉的anchor。

这样设置Anchors是为了：

1. **保证在x方向上，Anchor覆盖原图每个点且不相互重叠。**
2. **不同文本在y方向上高度差距很大，所以设置Anchors高度为11-283，用于覆盖不同高度的文本目标。**

注意：
**anchor的宽度和原始的特征图是一样的。**

这是因为Anchor是目标的候选框，经过后续分类+位置修正获得目标在原图尺度的检测框。那么这就要求Anchor必须是对应原图尺度！除此之外，如果Anchor大小对应conv5/fc尺度，那就要求Bounding box regression把很小的框回归到很大，这已经超出Regression小范围修正框的设计目的。


获得Anchor后，与Faster R-CNN类似，CTPN会做如下处理：

1. Softmax判断Anchor中是否包含文本，即选出Softmax score大的正Anchor
2. Bounding box regression修正包含文本的Anchor的**中心y坐标**与**高度**。


Anchor经过上述Softmax和y方向bounding box regeression处理后，会获得图7所示的一组竖直条状text proposal。后续只需要将这些text proposal用文本线构造算法连接在一起即可获得文本位置。

![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/31cbcc0b9f0f33d5fab222466e1742b2.png)



### 文本区域构造算法

在CTPN中对文本选取构建小的文本区域，最后得到关于原始图像特征的anchor集合，在完成这一部分之后，还需要对这些小的文本区域进行归并得到完整的文本区域，关于这个完整的文本区域，使用如下的构造方法。

在上一个步骤中，已经获得了一串或多串text proposal，接下来就要采用文本线构造办法，把这些text proposal连接成一个文本检测框。

整个文本区域构造算法的核心思路是：**先顺序找，再逆序找，比较区域得分确定区间长度。**

![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/32522580425530dbcaffbb5b5f821743.png)


如上图所示：

1. 按照水平x坐标排序Anchor。
2. 计算每个anchor Xi的pair(Xj)组成pair(Xi,Xj)。
3. 通过每个pair(Xi,Xj)构成一个content graph，最终获得文本检测框。


规则：
1. 分为向前和向后两部分。
2. 先向前走，基于重合度（>=0.7）与位置距离（50）寻找合适的anchor距离，找到最大的Xj.
3. 从Xj再返回寻找，到Xi。
4. 如果Score*i* > Score*j* 则这是一个长序列，否则应该被更长的序列包围。

例如下图：
![小杜的个人图床](http://src.xiaodu0.com/2024/04/21/e55ef21241b7a31df4894592ec46ef71.png)

##  CRNN网络架构

CRNN实际上就是CNN+RNN  通过CNN进行特征提取，接下俩由RNN进行序列特征提取，最后得出预测结果即可。

CRNN模型结合了CNN模型与RNN模型，**CNN用于提取图像特征，RNN将CNN提取的特征进行处理得到输出，对应最终的标签**。
CRNN包含三层，**卷积层，循环层和转录层**，由于每张图像中英文单词的长度不一致，但是经过CNN之后提取的特征长度是一定的，所以就需要一个转录层处理，得到最终结果。

CRNN的结构：
![小杜的个人图床](http://src.xiaodu0.com/2024/04/22/b210c4370cce2b2b7936800697763c90.png)

简单来说上图包含的三个层级结构分别是：

**Convolutional Layers(卷积层):用于对输入的图像提取特征图。**
**Recurrent Layers(循环层):通过RNN得到特征序列的结果。**
**Transcription Layers(转录层):将最终结果输出。**


**在CNN中还涉及了CTC模块，用于对齐输入和输出结果。**

实际上CTC是为了解决由于输入标签过多或者过少，而期望的结果小于或者大于输入的情况。例如在一个含有"hello world"的图片中，每次单词之间有空格，或者单词过于紧凑，对这样一个十个词的图片，划分了20个左右的文本区域，这时候如果直接输出的话是24个文本区域的内容，但是原先的图片中只包含10个字符，因此通过CTC对结果进行对齐。



## 训练数据和环境准备

